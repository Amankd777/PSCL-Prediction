{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZoOOLtmXiNa"
      },
      "source": [
        "### Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hy82CKn9WVrI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8wMeqqgXMUX"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Dataset-20230913T110643Z-001/Dataset/Benchmark_BinaryML.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4v-BBptMXcaB",
        "outputId": "a729f6e3-50fa-46a0-95aa-aa024cdab079"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 578,\n  \"fields\": [\n    {\n      \"column\": \"PDBid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 578,\n        \"samples\": [\n          \"P51321\",\n          \"P54150\",\n          \"B9DFX7\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 578,\n        \"samples\": [\n          \"MTFAFSKKIELKPILKFDTPKVYSYEIIQEIEALVQRLFLQVWRRPATLMAGIIQPLLWLVLFGGLFCNAPVNLFTINTSYNRFLSSGIIVFTSFTGALNSGLPLMFDREFGFLNRLLTAPLISRTSIIFSSATFMTCLSLIQVIFIVIASLFMGNSPLSSNSTLIFALIVLLVTVGVTMLSLALSFTLPGHIELLALILVVNLPFLFSSTALAPLYFMPPWLQLIASLNPLSYAIEGIRYIYSNTDWNFTESVIKISWGDISLGQIISLLLFLDVIGAYIVSNILKARLN\",\n          \"MQVLVVSPPLIAAASLSKPLNSLSKAALSFSRAKPICPFPQTSRRPISVYKSPMNNLFNRLGFGSRPQAQADPSSAAIAQGPDDDVPSSGQQFAQFGAGCFWGVELAYQRVPGVTKTEVGYSHGIVHNPSYEDVCTGTTGHNEVVRVQYDPKECSFESLLDVFWNRHDPTTLNRQGGDVGTQYRSGIYYYTDEQERIAREAVEKQQKILNKRIVTEILPATKFYRAENYHQQYLAKGGRMGLRQSAEKGCKDPIRCYG\",\n          \"MASNLLRFPLPPPSSLHIRPSKFLVNRCFPRLRRSRIRRHCSRPFFLVSNSVEISTQSFESTESSIESVKSITSDTPILLDVSGMMCGGCVARVKSVLMSDDRVASAVVNMLTETAAVKFKPEVEVTADTAESLAKRLTESGFEAKRRVSGMGVAENVKKWKEMVSKKEDLLVKSRNRVAFAWTLVALCCGSHTSHILHSLGIHIAHGGIWDLLHNSYVKGGLAVGALLGPGRELLFDGIKAFGKRSPNMNSLVGLGSMAAFSISLISLVNPELEWDASFFDEPVMLLGFVLLGRSLEERAKLQASTDMNELLSLISTQSRLVITSSDNNTPVDSVLSSDSICINVSVDDIRVGDSLLVLPGETFPVDGSVLAGRSVVDESMLTGESLPVFKEEGCSVSAGTINWDGPLRIKASSTGSNSTISKIVRMVEDAQGNAAPVQRLADAIAGPFVYTIMSLSAMTFAFWYYVGSHIFPDVLLNDIAGPDGDALALSLKLAVDVLVVSCPCALGLATPTAILIGTSLGAKRGYLIRGGDVLERLASIDCVALDKTGTLTEGRPVVSGVASLGYEEQEVLKMAAAVEKTATHPIAKAIVNEAESLNLKTPETRGQLTEPGFGTLAEIDGRFVAVGSLEWVSDRFLKKNDSSDMVKLESLLDHKLSNTSSTSRYSKTVVYVGREGEGIIGAIAISDCLRQDAEFTVARLQEKGIKTVLLSGDREGAVATVAKNVGIKSESTNYSLSPEKKFEFISNLQSSGHRVAMVGDGINDAPSLAQADVGIALKIEAQENAASNAASVILVRNKLSHVVDALSLAQATMSKVYQNLAWAIAYNVISIPIAAGVLLPQYDFAMTPSLSGGLMALSSIFVVSNSLLLQLHKSETSKNSL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"envelope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lumen\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plastoglobule\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stroma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thylakoid_membrane\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 441,\n        \"min\": 51,\n        \"max\": 3707,\n        \"num_unique_values\": 396,\n        \"samples\": [\n          371,\n          630\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-117968a4-bb20-4dc8-a60a-cc1373bd5c24\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PDBid</th>\n",
              "      <th>Sequence</th>\n",
              "      <th>envelope</th>\n",
              "      <th>lumen</th>\n",
              "      <th>plastoglobule</th>\n",
              "      <th>stroma</th>\n",
              "      <th>thylakoid_membrane</th>\n",
              "      <th>Sum</th>\n",
              "      <th>Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q2QD41</td>\n",
              "      <td>MIFSTFEHILTHISFSVISIVITIQLITLLINETVGLYVSSEKGMI...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q9LIK0</td>\n",
              "      <td>MSQSIQFSTPSHTPHLLHLPHSQFNRPLSSISFRRFPLTTIKYTSI...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q41643</td>\n",
              "      <td>MALAQKVASRPAVASRRGVVVVRASVESRRAVLGGLLASTVVALTS...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q8WHX1</td>\n",
              "      <td>MIGRLYMKKLKNLFLFLSSLCPVFPWISQISLVMPFGLYYGFLTAL...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O19901</td>\n",
              "      <td>MEQYILKLENSINILAFLGALVSSLFYWAKLTYYKQIQVFSLPKFC...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>573</th>\n",
              "      <td>O82245</td>\n",
              "      <td>MDSQDIRYRGGDDRDAATTAMAETERKSADDNKGKRDQKRAMAKRG...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>574</th>\n",
              "      <td>P54150</td>\n",
              "      <td>MQVLVVSPPLIAAASLSKPLNSLSKAALSFSRAKPICPFPQTSRRP...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>Q42687</td>\n",
              "      <td>MLAAKSIAGPRAFKASAVRAAPKAGRRTVVVMARKNEVSESYAKAL...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>Q949U7</td>\n",
              "      <td>MATSLSVSRFMSSSATVISVAKPLLSPTVSFTAPLSFTRSLAPNLS...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577</th>\n",
              "      <td>Q9FZ89</td>\n",
              "      <td>MGFVLICTCPPSSGVVVSQLHHHQFSAGVKSNELWFRPTRRTLISK...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>578 rows Ã— 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-117968a4-bb20-4dc8-a60a-cc1373bd5c24')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-117968a4-bb20-4dc8-a60a-cc1373bd5c24 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-117968a4-bb20-4dc8-a60a-cc1373bd5c24');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2a09778f-1a25-4457-9ff3-6000bf7074e6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a09778f-1a25-4457-9ff3-6000bf7074e6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2a09778f-1a25-4457-9ff3-6000bf7074e6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      PDBid                                           Sequence  envelope  \\\n",
              "0    Q2QD41  MIFSTFEHILTHISFSVISIVITIQLITLLINETVGLYVSSEKGMI...         0   \n",
              "1    Q9LIK0  MSQSIQFSTPSHTPHLLHLPHSQFNRPLSSISFRRFPLTTIKYTSI...         0   \n",
              "2    Q41643  MALAQKVASRPAVASRRGVVVVRASVESRRAVLGGLLASTVVALTS...         0   \n",
              "3    Q8WHX1  MIGRLYMKKLKNLFLFLSSLCPVFPWISQISLVMPFGLYYGFLTAL...         1   \n",
              "4    O19901  MEQYILKLENSINILAFLGALVSSLFYWAKLTYYKQIQVFSLPKFC...         0   \n",
              "..      ...                                                ...       ...   \n",
              "573  O82245  MDSQDIRYRGGDDRDAATTAMAETERKSADDNKGKRDQKRAMAKRG...         1   \n",
              "574  P54150  MQVLVVSPPLIAAASLSKPLNSLSKAALSFSRAKPICPFPQTSRRP...         0   \n",
              "575  Q42687  MLAAKSIAGPRAFKASAVRAAPKAGRRTVVVMARKNEVSESYAKAL...         0   \n",
              "576  Q949U7  MATSLSVSRFMSSSATVISVAKPLLSPTVSFTAPLSFTRSLAPNLS...         0   \n",
              "577  Q9FZ89  MGFVLICTCPPSSGVVVSQLHHHQFSAGVKSNELWFRPTRRTLISK...         0   \n",
              "\n",
              "     lumen  plastoglobule  stroma  thylakoid_membrane  Sum  Length  \n",
              "0        0              0       0                   1    1     323  \n",
              "1        0              0       1                   0    1     596  \n",
              "2        0              0       0                   1    1     202  \n",
              "3        0              0       0                   0    1    1703  \n",
              "4        0              0       0                   1    1     293  \n",
              "..     ...            ...     ...                 ...  ...     ...  \n",
              "573      0              0       0                   0    1     196  \n",
              "574      0              0       1                   0    1     258  \n",
              "575      0              0       0                   1    1     219  \n",
              "576      0              0       1                   0    1     234  \n",
              "577      0              1       0                   0    1     123  \n",
              "\n",
              "[578 rows x 9 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "AgJVsz9aXdms",
        "outputId": "78dc77f3-a5b4-4231-c2fb-cf9c01f69729"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"mul_df\",\n  \"rows\": 23,\n  \"fields\": [\n    {\n      \"column\": \"PDBid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"O04921\",\n          \"Q9LU86\",\n          \"P21218\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"MNCPAMTASPSSSSSSSYSTFRPPPPLLPQLSNDSQRSVVMHCTRLPFEAFAATSSNRLLGKHSLPLRAALVTSNPLNISSSSVISDAISSSSVITDDAKIGVLLLNLGGPETLDDVQPFLFNLFADPDIIRLPPVFQFLQKPLAQFISVARAPKSKEGYASIGGGSPLRHITDAQAEELRKCLWEKNVPAKVYVGMRYWHPFTEEAIEQIKRDGITKLVVLPLYPQFSISTSGSSLRLLERIFREDEYLVNMQHTVIPSWYQREGYIKAMANLIQSELGKFGSPNQVVIFFSAHGVPLAYVEEAGDPYKAEMEECVDLIMEELDKRKITNAYTLAYQSRVGPVEWLKPYTEEAITELGKKGVENLLAVPISFVSEHIETLEEIDVEYKELALKSGIKNWGRVPALGTEPMFISDLADAVVESLPYVGAMAVSNLEARQSLVPLGSVEELLATYDSQRRELPAPVTMWEWGWTKSAETWNGRAAMLAVLALLVLEVTTGKGFLHQWGILPSL\",\n          \"MAASSSSFTLCNHTTLRTLPLRKTLVTKTQFSVPTKSSESNFFGSTLTHSSYISPVSSSSLKGLIFAKVNKGQAAPDFTLKDQNGKPVSLKKYKGKPVVLYFYPADETPGCTKQACAFRDSYEKFKKAGAEVIGISGDDSASHKAFASKYKLPYTLLSDEGNKVRKDWGVPGDLFGALPGRQTYVLDKNGVVQLIYNNQFQPEKHIDETLKFLKAA\",\n          \"MALQAASLVSSAFSVRKDAKLNASSSSFKDSSLFGASITDQIKSEHGSSSLRFKREQSLRNLAIRAQTAATSSPTVTKSVDGKKTLRKGNVVVTGASSGLGLATAKALAETGKWNVIMACRDFLKAERAAKSVGMPKDSYTVMHLDLASLDSVRQFVDNFRRTETPLDVLVCNAAVYFPTAKEPTYSAEGFELSVATNHLGHFLLARLLLDDLKKSDYPSKRLIIVGSITGNTNTLAGNVPPKANLGDLRGLAGGLNGLNSSAMIDGGDFDGAKAYKDSKVCNMLTMQEFHRRFHEETGVTFASLYPGCIASTGLFREHIPLFRALFPPFQKYITKGYVSETESGKRLAQVVSDPSLTKSGVYWSWNNASASFENQLSEEASDVEKARKVWEISEKLVGLA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"envelope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lumen\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plastoglobule\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stroma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thylakoid_membrane\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 193,\n        \"min\": 175,\n        \"max\": 945,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          512,\n          216\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "mul_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-37e32507-6023-4ee4-980b-f3d7c38ec386\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PDBid</th>\n",
              "      <th>Sequence</th>\n",
              "      <th>envelope</th>\n",
              "      <th>lumen</th>\n",
              "      <th>plastoglobule</th>\n",
              "      <th>stroma</th>\n",
              "      <th>thylakoid_membrane</th>\n",
              "      <th>Sum</th>\n",
              "      <th>Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>P21218</td>\n",
              "      <td>MALQAASLVSSAFSVRKDAKLNASSSSFKDSSLFGASITDQIKSEH...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>Q8W493</td>\n",
              "      <td>MATTMNAAVSLTSSNSSSFPATSCAIAPERIRFTKGAFYYKSNNVV...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>P42762</td>\n",
              "      <td>MEVLSTSSPLTLHSHRLLSASSSSSHVTSIAASSLSSFASSYLGIS...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>O80842</td>\n",
              "      <td>MATSSAHLSFLAGRISPFSSERIGLFPLRGEFRPRMTRFRCSAGPS...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>Q9FGC7</td>\n",
              "      <td>MGSTPFCYSINPSPSKLDFTRTHVFSPVSKQFYLDLSSFSGKPGGV...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>P10896</td>\n",
              "      <td>MAAAVSTVGAINRAPLSLNGSGSGAVSAPASTFLGKKVVTVSRFAQ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>Q9ZWM5</td>\n",
              "      <td>MLPASLQRKAAAVGGRGPTNQSRVAVRVSAQPKEAPPASTPIVEDP...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>O82533</td>\n",
              "      <td>MATYVSPCFTPSDSRLLTVLRKNVLPENHLGRLNSIRTIDSKKNRV...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>O80796</td>\n",
              "      <td>MALKASPVTGLFPPLRPTASSSPSTSSNRPCSLRILPLRTSFFGNS...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>Q9LU86</td>\n",
              "      <td>MAASSSSFTLCNHTTLRTLPLRKTLVTKTQFSVPTKSSESNFFGST...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>Q8S7E1</td>\n",
              "      <td>MTTVASLSLLPHLLIKPSFRCCSRKGVGRYGGIKVYAVLGDDGADY...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>Q8H0U5</td>\n",
              "      <td>MEGTCFLRGQPLTTIPSLPSRKGFLLQRWKTNRIVRFSGFKNHSVS...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>P25857</td>\n",
              "      <td>MATHAALAVSRIPVTQRLQSKSAIHSFPAQCSSKRLEVAEFSGLRM...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>F4IQV7</td>\n",
              "      <td>MNSSQACFFHFSLRPISLSHPSYAFLSKRDPFLCSQPRKCLTTNLN...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>Q8H0W1</td>\n",
              "      <td>MMVMISLHFSTPPLAFLKSDSNSRFLKNPNPNFIQFTPKSQLLFPQ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>O04921</td>\n",
              "      <td>MNCPAMTASPSSSSSSSYSTFRPPPPLLPQLSNDSQRSVVMHCTRL...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>Q6F6B5</td>\n",
              "      <td>MPISMELPVFSTLRVPLFSRLALLPTFGVPFSSLGATTRLNCTSRK...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>Q9SKT0</td>\n",
              "      <td>MAATAISSLSFPALGQSDKISNFASSRPLASAIRICTKFSRLSLNS...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>P56765</td>\n",
              "      <td>MEKSWFNFMFSKGELEYRGELSKAMDSFAPGEKTTISQDRFIYDMD...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>Q9M024</td>\n",
              "      <td>MGEEKSLLQFRSFPSLKTSDFALTEEPSWRLENNVSSNRRRGNKRS...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>P21276</td>\n",
              "      <td>MAASSAVTANYVLKPPPFALDALEPHMSKQTLEFHWGKHHRAYVDN...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>543</th>\n",
              "      <td>P10796</td>\n",
              "      <td>MASSMLSSAAVVTSPAQATMVAPFTGLKSSASFPVTRKANNDITSI...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>Q8VY88</td>\n",
              "      <td>MASSSISFSCAPSLATSLFSTTSSSPRLLSSRFLGTRNLKLRIRPA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>175</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37e32507-6023-4ee4-980b-f3d7c38ec386')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37e32507-6023-4ee4-980b-f3d7c38ec386 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37e32507-6023-4ee4-980b-f3d7c38ec386');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-09636378-a9bb-4405-a355-d1546a5d6562\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09636378-a9bb-4405-a355-d1546a5d6562')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-09636378-a9bb-4405-a355-d1546a5d6562 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      PDBid                                           Sequence  envelope  \\\n",
              "41   P21218  MALQAASLVSSAFSVRKDAKLNASSSSFKDSSLFGASITDQIKSEH...         1   \n",
              "111  Q8W493  MATTMNAAVSLTSSNSSSFPATSCAIAPERIRFTKGAFYYKSNNVV...         0   \n",
              "114  P42762  MEVLSTSSPLTLHSHRLLSASSSSSHVTSIAASSLSSFASSYLGIS...         0   \n",
              "161  O80842  MATSSAHLSFLAGRISPFSSERIGLFPLRGEFRPRMTRFRCSAGPS...         0   \n",
              "203  Q9FGC7  MGSTPFCYSINPSPSKLDFTRTHVFSPVSKQFYLDLSSFSGKPGGV...         1   \n",
              "245  P10896  MAAAVSTVGAINRAPLSLNGSGSGAVSAPASTFLGKKVVTVSRFAQ...         0   \n",
              "262  Q9ZWM5  MLPASLQRKAAAVGGRGPTNQSRVAVRVSAQPKEAPPASTPIVEDP...         1   \n",
              "264  O82533  MATYVSPCFTPSDSRLLTVLRKNVLPENHLGRLNSIRTIDSKKNRV...         0   \n",
              "268  O80796  MALKASPVTGLFPPLRPTASSSPSTSSNRPCSLRILPLRTSFFGNS...         1   \n",
              "292  Q9LU86  MAASSSSFTLCNHTTLRTLPLRKTLVTKTQFSVPTKSSESNFFGST...         0   \n",
              "306  Q8S7E1  MTTVASLSLLPHLLIKPSFRCCSRKGVGRYGGIKVYAVLGDDGADY...         1   \n",
              "316  Q8H0U5  MEGTCFLRGQPLTTIPSLPSRKGFLLQRWKTNRIVRFSGFKNHSVS...         1   \n",
              "321  P25857  MATHAALAVSRIPVTQRLQSKSAIHSFPAQCSSKRLEVAEFSGLRM...         1   \n",
              "376  F4IQV7  MNSSQACFFHFSLRPISLSHPSYAFLSKRDPFLCSQPRKCLTTNLN...         1   \n",
              "382  Q8H0W1  MMVMISLHFSTPPLAFLKSDSNSRFLKNPNPNFIQFTPKSQLLFPQ...         1   \n",
              "403  O04921  MNCPAMTASPSSSSSSSYSTFRPPPPLLPQLSNDSQRSVVMHCTRL...         1   \n",
              "441  Q6F6B5  MPISMELPVFSTLRVPLFSRLALLPTFGVPFSSLGATTRLNCTSRK...         1   \n",
              "458  Q9SKT0  MAATAISSLSFPALGQSDKISNFASSRPLASAIRICTKFSRLSLNS...         1   \n",
              "467  P56765  MEKSWFNFMFSKGELEYRGELSKAMDSFAPGEKTTISQDRFIYDMD...         1   \n",
              "499  Q9M024  MGEEKSLLQFRSFPSLKTSDFALTEEPSWRLENNVSSNRRRGNKRS...         1   \n",
              "525  P21276  MAASSAVTANYVLKPPPFALDALEPHMSKQTLEFHWGKHHRAYVDN...         1   \n",
              "543  P10796  MASSMLSSAAVVTSPAQATMVAPFTGLKSSASFPVTRKANNDITSI...         1   \n",
              "553  Q8VY88  MASSSISFSCAPSLATSLFSTTSSSPRLLSSRFLGTRNLKLRIRPA...         1   \n",
              "\n",
              "     lumen  plastoglobule  stroma  thylakoid_membrane  Sum  Length  \n",
              "41       0              0       0                   1    2     401  \n",
              "111      0              0       1                   1    2     369  \n",
              "114      0              0       1                   1    2     945  \n",
              "161      0              0       1                   1    2     366  \n",
              "203      0              0       0                   1    2     667  \n",
              "245      0              1       1                   0    2     474  \n",
              "262      0              0       0                   1    2     645  \n",
              "264      0              0       1                   1    2     478  \n",
              "268      0              0       0                   1    2     330  \n",
              "292      1              1       0                   0    2     216  \n",
              "306      0              0       0                   1    2     541  \n",
              "316      0              0       1                   0    2     641  \n",
              "321      0              0       1                   0    2     447  \n",
              "376      0              0       0                   1    2     575  \n",
              "382      0              0       0                   1    2     291  \n",
              "403      0              0       0                   1    2     512  \n",
              "441      0              0       1                   0    2     741  \n",
              "458      0              0       1                   0    2     300  \n",
              "467      0              0       1                   0    2     488  \n",
              "499      0              0       0                   1    2     415  \n",
              "525      0              0       1                   0    2     212  \n",
              "543      0              0       1                   0    2     181  \n",
              "553      0              0       1                   1    3     175  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mul_df=df[df['Sum']>1]\n",
        "mul_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YM0j5zrX6Pp",
        "outputId": "59e581d9-c4d9-4916-8600-4919d26623c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(23, 9)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mul_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWxFfWoCYtCY",
        "outputId": "696aa187-9c3e-47ac-826f-a28f1d1897b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PDBid                 0\n",
              "Sequence              0\n",
              "envelope              0\n",
              "lumen                 0\n",
              "plastoglobule         0\n",
              "stroma                0\n",
              "thylakoid_membrane    0\n",
              "Sum                   0\n",
              "Length                0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV_UgcPmY8JU",
        "outputId": "3e1f6713-1eb0-4cfe-895e-070c2cc85017"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(548, 9)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['plastoglobule']==0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "725Q_66bcXl1"
      },
      "outputs": [],
      "source": [
        "data=[]\n",
        "for i in df['Sequence']:\n",
        "  data.append(len(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RSrtNDgdwC_",
        "outputId": "47a835df-cfc3-4d8d-9993-7fe51efa21c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3707"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.sort()\n",
        "data[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FzkX763RdBlR",
        "outputId": "c4af033d-0582-4a2a-c54b-fde23eb90e5a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# For histogram\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(data, bins=10, edgecolor='black')\n",
        "plt.title('Histogram of Data')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# For bar chart\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(range(len(data)), data)\n",
        "plt.title('Bar Chart of Data')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9T-mtoti7XD"
      },
      "source": [
        "## N-grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJsQpDzpeVbG"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRbSYtWgi_Ru"
      },
      "outputs": [],
      "source": [
        "# Function to generate n-grams for a given sequence\n",
        "def generate_ngrams(sequence, n):\n",
        "    tokens = [char for char in sequence]\n",
        "    n_grams = list(ngrams(tokens, n))\n",
        "    n_grams = [''.join(gram) for gram in n_grams]\n",
        "    return n_grams\n",
        "\n",
        "# Generate bi and trigrams for each input sequence\n",
        "bi_grams = []\n",
        "tri_grams = []\n",
        "\n",
        "for sequence in df['Sequence']:\n",
        "    bi_grams.append(generate_ngrams(sequence, 2))\n",
        "    tri_grams.append(generate_ngrams(sequence, 3))\n",
        "\n",
        "\n",
        "df['Bi-grams'] = bi_grams\n",
        "df['Tri-grams'] = tri_grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "LFptweAkl8H5",
        "outputId": "b7dae016-034c-4742-baf5-1f857537c5d2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 578,\n  \"fields\": [\n    {\n      \"column\": \"PDBid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 578,\n        \"samples\": [\n          \"P51321\",\n          \"P54150\",\n          \"B9DFX7\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 578,\n        \"samples\": [\n          \"MTFAFSKKIELKPILKFDTPKVYSYEIIQEIEALVQRLFLQVWRRPATLMAGIIQPLLWLVLFGGLFCNAPVNLFTINTSYNRFLSSGIIVFTSFTGALNSGLPLMFDREFGFLNRLLTAPLISRTSIIFSSATFMTCLSLIQVIFIVIASLFMGNSPLSSNSTLIFALIVLLVTVGVTMLSLALSFTLPGHIELLALILVVNLPFLFSSTALAPLYFMPPWLQLIASLNPLSYAIEGIRYIYSNTDWNFTESVIKISWGDISLGQIISLLLFLDVIGAYIVSNILKARLN\",\n          \"MQVLVVSPPLIAAASLSKPLNSLSKAALSFSRAKPICPFPQTSRRPISVYKSPMNNLFNRLGFGSRPQAQADPSSAAIAQGPDDDVPSSGQQFAQFGAGCFWGVELAYQRVPGVTKTEVGYSHGIVHNPSYEDVCTGTTGHNEVVRVQYDPKECSFESLLDVFWNRHDPTTLNRQGGDVGTQYRSGIYYYTDEQERIAREAVEKQQKILNKRIVTEILPATKFYRAENYHQQYLAKGGRMGLRQSAEKGCKDPIRCYG\",\n          \"MASNLLRFPLPPPSSLHIRPSKFLVNRCFPRLRRSRIRRHCSRPFFLVSNSVEISTQSFESTESSIESVKSITSDTPILLDVSGMMCGGCVARVKSVLMSDDRVASAVVNMLTETAAVKFKPEVEVTADTAESLAKRLTESGFEAKRRVSGMGVAENVKKWKEMVSKKEDLLVKSRNRVAFAWTLVALCCGSHTSHILHSLGIHIAHGGIWDLLHNSYVKGGLAVGALLGPGRELLFDGIKAFGKRSPNMNSLVGLGSMAAFSISLISLVNPELEWDASFFDEPVMLLGFVLLGRSLEERAKLQASTDMNELLSLISTQSRLVITSSDNNTPVDSVLSSDSICINVSVDDIRVGDSLLVLPGETFPVDGSVLAGRSVVDESMLTGESLPVFKEEGCSVSAGTINWDGPLRIKASSTGSNSTISKIVRMVEDAQGNAAPVQRLADAIAGPFVYTIMSLSAMTFAFWYYVGSHIFPDVLLNDIAGPDGDALALSLKLAVDVLVVSCPCALGLATPTAILIGTSLGAKRGYLIRGGDVLERLASIDCVALDKTGTLTEGRPVVSGVASLGYEEQEVLKMAAAVEKTATHPIAKAIVNEAESLNLKTPETRGQLTEPGFGTLAEIDGRFVAVGSLEWVSDRFLKKNDSSDMVKLESLLDHKLSNTSSTSRYSKTVVYVGREGEGIIGAIAISDCLRQDAEFTVARLQEKGIKTVLLSGDREGAVATVAKNVGIKSESTNYSLSPEKKFEFISNLQSSGHRVAMVGDGINDAPSLAQADVGIALKIEAQENAASNAASVILVRNKLSHVVDALSLAQATMSKVYQNLAWAIAYNVISIPIAAGVLLPQYDFAMTPSLSGGLMALSSIFVVSNSLLLQLHKSETSKNSL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"envelope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lumen\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plastoglobule\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stroma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thylakoid_membrane\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 441,\n        \"min\": 51,\n        \"max\": 3707,\n        \"num_unique_values\": 396,\n        \"samples\": [\n          371,\n          630\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bi-grams\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tri-grams\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-088400a4-04ac-480c-bb80-52882d60e32c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PDBid</th>\n",
              "      <th>Sequence</th>\n",
              "      <th>envelope</th>\n",
              "      <th>lumen</th>\n",
              "      <th>plastoglobule</th>\n",
              "      <th>stroma</th>\n",
              "      <th>thylakoid_membrane</th>\n",
              "      <th>Sum</th>\n",
              "      <th>Length</th>\n",
              "      <th>Bi-grams</th>\n",
              "      <th>Tri-grams</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q2QD41</td>\n",
              "      <td>MIFSTFEHILTHISFSVISIVITIQLITLLINETVGLYVSSEKGMI...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>323</td>\n",
              "      <td>[MI, IF, FS, ST, TF, FE, EH, HI, IL, LT, TH, H...</td>\n",
              "      <td>[MIF, IFS, FST, STF, TFE, FEH, EHI, HIL, ILT, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q9LIK0</td>\n",
              "      <td>MSQSIQFSTPSHTPHLLHLPHSQFNRPLSSISFRRFPLTTIKYTSI...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>596</td>\n",
              "      <td>[MS, SQ, QS, SI, IQ, QF, FS, ST, TP, PS, SH, H...</td>\n",
              "      <td>[MSQ, SQS, QSI, SIQ, IQF, QFS, FST, STP, TPS, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q41643</td>\n",
              "      <td>MALAQKVASRPAVASRRGVVVVRASVESRRAVLGGLLASTVVALTS...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>202</td>\n",
              "      <td>[MA, AL, LA, AQ, QK, KV, VA, AS, SR, RP, PA, A...</td>\n",
              "      <td>[MAL, ALA, LAQ, AQK, QKV, KVA, VAS, ASR, SRP, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q8WHX1</td>\n",
              "      <td>MIGRLYMKKLKNLFLFLSSLCPVFPWISQISLVMPFGLYYGFLTAL...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1703</td>\n",
              "      <td>[MI, IG, GR, RL, LY, YM, MK, KK, KL, LK, KN, N...</td>\n",
              "      <td>[MIG, IGR, GRL, RLY, LYM, YMK, MKK, KKL, KLK, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O19901</td>\n",
              "      <td>MEQYILKLENSINILAFLGALVSSLFYWAKLTYYKQIQVFSLPKFC...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>293</td>\n",
              "      <td>[ME, EQ, QY, YI, IL, LK, KL, LE, EN, NS, SI, I...</td>\n",
              "      <td>[MEQ, EQY, QYI, YIL, ILK, LKL, KLE, LEN, ENS, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>573</th>\n",
              "      <td>O82245</td>\n",
              "      <td>MDSQDIRYRGGDDRDAATTAMAETERKSADDNKGKRDQKRAMAKRG...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>196</td>\n",
              "      <td>[MD, DS, SQ, QD, DI, IR, RY, YR, RG, GG, GD, D...</td>\n",
              "      <td>[MDS, DSQ, SQD, QDI, DIR, IRY, RYR, YRG, RGG, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>574</th>\n",
              "      <td>P54150</td>\n",
              "      <td>MQVLVVSPPLIAAASLSKPLNSLSKAALSFSRAKPICPFPQTSRRP...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>258</td>\n",
              "      <td>[MQ, QV, VL, LV, VV, VS, SP, PP, PL, LI, IA, A...</td>\n",
              "      <td>[MQV, QVL, VLV, LVV, VVS, VSP, SPP, PPL, PLI, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>Q42687</td>\n",
              "      <td>MLAAKSIAGPRAFKASAVRAAPKAGRRTVVVMARKNEVSESYAKAL...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>219</td>\n",
              "      <td>[ML, LA, AA, AK, KS, SI, IA, AG, GP, PR, RA, A...</td>\n",
              "      <td>[MLA, LAA, AAK, AKS, KSI, SIA, IAG, AGP, GPR, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>Q949U7</td>\n",
              "      <td>MATSLSVSRFMSSSATVISVAKPLLSPTVSFTAPLSFTRSLAPNLS...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>234</td>\n",
              "      <td>[MA, AT, TS, SL, LS, SV, VS, SR, RF, FM, MS, S...</td>\n",
              "      <td>[MAT, ATS, TSL, SLS, LSV, SVS, VSR, SRF, RFM, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577</th>\n",
              "      <td>Q9FZ89</td>\n",
              "      <td>MGFVLICTCPPSSGVVVSQLHHHQFSAGVKSNELWFRPTRRTLISK...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>123</td>\n",
              "      <td>[MG, GF, FV, VL, LI, IC, CT, TC, CP, PP, PS, S...</td>\n",
              "      <td>[MGF, GFV, FVL, VLI, LIC, ICT, CTC, TCP, CPP, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>578 rows Ã— 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-088400a4-04ac-480c-bb80-52882d60e32c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-088400a4-04ac-480c-bb80-52882d60e32c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-088400a4-04ac-480c-bb80-52882d60e32c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e180ba37-f880-4b3d-af6e-e9fad8342a08\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e180ba37-f880-4b3d-af6e-e9fad8342a08')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e180ba37-f880-4b3d-af6e-e9fad8342a08 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      PDBid                                           Sequence  envelope  \\\n",
              "0    Q2QD41  MIFSTFEHILTHISFSVISIVITIQLITLLINETVGLYVSSEKGMI...         0   \n",
              "1    Q9LIK0  MSQSIQFSTPSHTPHLLHLPHSQFNRPLSSISFRRFPLTTIKYTSI...         0   \n",
              "2    Q41643  MALAQKVASRPAVASRRGVVVVRASVESRRAVLGGLLASTVVALTS...         0   \n",
              "3    Q8WHX1  MIGRLYMKKLKNLFLFLSSLCPVFPWISQISLVMPFGLYYGFLTAL...         1   \n",
              "4    O19901  MEQYILKLENSINILAFLGALVSSLFYWAKLTYYKQIQVFSLPKFC...         0   \n",
              "..      ...                                                ...       ...   \n",
              "573  O82245  MDSQDIRYRGGDDRDAATTAMAETERKSADDNKGKRDQKRAMAKRG...         1   \n",
              "574  P54150  MQVLVVSPPLIAAASLSKPLNSLSKAALSFSRAKPICPFPQTSRRP...         0   \n",
              "575  Q42687  MLAAKSIAGPRAFKASAVRAAPKAGRRTVVVMARKNEVSESYAKAL...         0   \n",
              "576  Q949U7  MATSLSVSRFMSSSATVISVAKPLLSPTVSFTAPLSFTRSLAPNLS...         0   \n",
              "577  Q9FZ89  MGFVLICTCPPSSGVVVSQLHHHQFSAGVKSNELWFRPTRRTLISK...         0   \n",
              "\n",
              "     lumen  plastoglobule  stroma  thylakoid_membrane  Sum  Length  \\\n",
              "0        0              0       0                   1    1     323   \n",
              "1        0              0       1                   0    1     596   \n",
              "2        0              0       0                   1    1     202   \n",
              "3        0              0       0                   0    1    1703   \n",
              "4        0              0       0                   1    1     293   \n",
              "..     ...            ...     ...                 ...  ...     ...   \n",
              "573      0              0       0                   0    1     196   \n",
              "574      0              0       1                   0    1     258   \n",
              "575      0              0       0                   1    1     219   \n",
              "576      0              0       1                   0    1     234   \n",
              "577      0              1       0                   0    1     123   \n",
              "\n",
              "                                              Bi-grams  \\\n",
              "0    [MI, IF, FS, ST, TF, FE, EH, HI, IL, LT, TH, H...   \n",
              "1    [MS, SQ, QS, SI, IQ, QF, FS, ST, TP, PS, SH, H...   \n",
              "2    [MA, AL, LA, AQ, QK, KV, VA, AS, SR, RP, PA, A...   \n",
              "3    [MI, IG, GR, RL, LY, YM, MK, KK, KL, LK, KN, N...   \n",
              "4    [ME, EQ, QY, YI, IL, LK, KL, LE, EN, NS, SI, I...   \n",
              "..                                                 ...   \n",
              "573  [MD, DS, SQ, QD, DI, IR, RY, YR, RG, GG, GD, D...   \n",
              "574  [MQ, QV, VL, LV, VV, VS, SP, PP, PL, LI, IA, A...   \n",
              "575  [ML, LA, AA, AK, KS, SI, IA, AG, GP, PR, RA, A...   \n",
              "576  [MA, AT, TS, SL, LS, SV, VS, SR, RF, FM, MS, S...   \n",
              "577  [MG, GF, FV, VL, LI, IC, CT, TC, CP, PP, PS, S...   \n",
              "\n",
              "                                             Tri-grams  \n",
              "0    [MIF, IFS, FST, STF, TFE, FEH, EHI, HIL, ILT, ...  \n",
              "1    [MSQ, SQS, QSI, SIQ, IQF, QFS, FST, STP, TPS, ...  \n",
              "2    [MAL, ALA, LAQ, AQK, QKV, KVA, VAS, ASR, SRP, ...  \n",
              "3    [MIG, IGR, GRL, RLY, LYM, YMK, MKK, KKL, KLK, ...  \n",
              "4    [MEQ, EQY, QYI, YIL, ILK, LKL, KLE, LEN, ENS, ...  \n",
              "..                                                 ...  \n",
              "573  [MDS, DSQ, SQD, QDI, DIR, IRY, RYR, YRG, RGG, ...  \n",
              "574  [MQV, QVL, VLV, LVV, VVS, VSP, SPP, PPL, PLI, ...  \n",
              "575  [MLA, LAA, AAK, AKS, KSI, SIA, IAG, AGP, GPR, ...  \n",
              "576  [MAT, ATS, TSL, SLS, LSV, SVS, VSR, SRF, RFM, ...  \n",
              "577  [MGF, GFV, FVL, VLI, LIC, ICT, CTC, TCP, CPP, ...  \n",
              "\n",
              "[578 rows x 11 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6_MaElzmJe5"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSBZAMoMol7o"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(bi_grams, vector_size=20, window=7, min_count=1, sg=0, epochs=50)  # Adjust parameters as needed\n",
        "\n",
        "# Extract embeddings for each token in the 2-grams\n",
        "def get_embedding(token):\n",
        "    try:\n",
        "        return model.wv[token].tolist()\n",
        "    except KeyError:\n",
        "        # Handle the case where the token is not in the vocabulary\n",
        "        return [0.0] * 100  # Return a vector of zeros of the same dimension as your model\n",
        "\n",
        "# Create a new column 'embeddings' containing embeddings for each 2-gram\n",
        "df['Bi-embeds'] = df['Bi-grams'].apply(lambda tokens: [get_embedding(token) for token in tokens])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk-E1nHRtTeS"
      },
      "outputs": [],
      "source": [
        "model1 = Word2Vec(tri_grams, vector_size=20, window=7, min_count=1, sg=0, epochs=50)  # Adjust parameters as needed\n",
        "\n",
        "# Extract embeddings for each token in the 2-grams\n",
        "def get_embedding(token):\n",
        "    try:\n",
        "        return model1.wv[token].tolist()\n",
        "    except KeyError:\n",
        "        # Handle the case where the token is not in the vocabulary\n",
        "        return [0.0] * 100  # Return a vector of zeros of the same dimension as your model\n",
        "\n",
        "# Create a new column 'embeddings' containing embeddings for each 2-gram\n",
        "df['Tri-embeds'] = df['Tri-grams'].apply(lambda tokens: [get_embedding(token) for token in tokens])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skCFT_0sti4-",
        "outputId": "f7752494-fec3-4217-b7ce-5000cbb982c5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 578,\n  \"fields\": [\n    {\n      \"column\": \"PDBid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 578,\n        \"samples\": [\n          \"P51321\",\n          \"P54150\",\n          \"B9DFX7\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 578,\n        \"samples\": [\n          \"MTFAFSKKIELKPILKFDTPKVYSYEIIQEIEALVQRLFLQVWRRPATLMAGIIQPLLWLVLFGGLFCNAPVNLFTINTSYNRFLSSGIIVFTSFTGALNSGLPLMFDREFGFLNRLLTAPLISRTSIIFSSATFMTCLSLIQVIFIVIASLFMGNSPLSSNSTLIFALIVLLVTVGVTMLSLALSFTLPGHIELLALILVVNLPFLFSSTALAPLYFMPPWLQLIASLNPLSYAIEGIRYIYSNTDWNFTESVIKISWGDISLGQIISLLLFLDVIGAYIVSNILKARLN\",\n          \"MQVLVVSPPLIAAASLSKPLNSLSKAALSFSRAKPICPFPQTSRRPISVYKSPMNNLFNRLGFGSRPQAQADPSSAAIAQGPDDDVPSSGQQFAQFGAGCFWGVELAYQRVPGVTKTEVGYSHGIVHNPSYEDVCTGTTGHNEVVRVQYDPKECSFESLLDVFWNRHDPTTLNRQGGDVGTQYRSGIYYYTDEQERIAREAVEKQQKILNKRIVTEILPATKFYRAENYHQQYLAKGGRMGLRQSAEKGCKDPIRCYG\",\n          \"MASNLLRFPLPPPSSLHIRPSKFLVNRCFPRLRRSRIRRHCSRPFFLVSNSVEISTQSFESTESSIESVKSITSDTPILLDVSGMMCGGCVARVKSVLMSDDRVASAVVNMLTETAAVKFKPEVEVTADTAESLAKRLTESGFEAKRRVSGMGVAENVKKWKEMVSKKEDLLVKSRNRVAFAWTLVALCCGSHTSHILHSLGIHIAHGGIWDLLHNSYVKGGLAVGALLGPGRELLFDGIKAFGKRSPNMNSLVGLGSMAAFSISLISLVNPELEWDASFFDEPVMLLGFVLLGRSLEERAKLQASTDMNELLSLISTQSRLVITSSDNNTPVDSVLSSDSICINVSVDDIRVGDSLLVLPGETFPVDGSVLAGRSVVDESMLTGESLPVFKEEGCSVSAGTINWDGPLRIKASSTGSNSTISKIVRMVEDAQGNAAPVQRLADAIAGPFVYTIMSLSAMTFAFWYYVGSHIFPDVLLNDIAGPDGDALALSLKLAVDVLVVSCPCALGLATPTAILIGTSLGAKRGYLIRGGDVLERLASIDCVALDKTGTLTEGRPVVSGVASLGYEEQEVLKMAAAVEKTATHPIAKAIVNEAESLNLKTPETRGQLTEPGFGTLAEIDGRFVAVGSLEWVSDRFLKKNDSSDMVKLESLLDHKLSNTSSTSRYSKTVVYVGREGEGIIGAIAISDCLRQDAEFTVARLQEKGIKTVLLSGDREGAVATVAKNVGIKSESTNYSLSPEKKFEFISNLQSSGHRVAMVGDGINDAPSLAQADVGIALKIEAQENAASNAASVILVRNKLSHVVDALSLAQATMSKVYQNLAWAIAYNVISIPIAAGVLLPQYDFAMTPSLSGGLMALSSIFVVSNSLLLQLHKSETSKNSL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"envelope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lumen\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plastoglobule\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stroma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thylakoid_membrane\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 441,\n        \"min\": 51,\n        \"max\": 3707,\n        \"num_unique_values\": 396,\n        \"samples\": [\n          371,\n          630\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bi-grams\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tri-grams\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bi-embeds\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tri-embeds\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f93e24c8-6f55-4259-a033-6b2a6b4aa1eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PDBid</th>\n",
              "      <th>Sequence</th>\n",
              "      <th>envelope</th>\n",
              "      <th>lumen</th>\n",
              "      <th>plastoglobule</th>\n",
              "      <th>stroma</th>\n",
              "      <th>thylakoid_membrane</th>\n",
              "      <th>Sum</th>\n",
              "      <th>Length</th>\n",
              "      <th>Bi-grams</th>\n",
              "      <th>Tri-grams</th>\n",
              "      <th>Bi-embeds</th>\n",
              "      <th>Tri-embeds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q2QD41</td>\n",
              "      <td>MIFSTFEHILTHISFSVISIVITIQLITLLINETVGLYVSSEKGMI...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>323</td>\n",
              "      <td>[MI, IF, FS, ST, TF, FE, EH, HI, IL, LT, TH, H...</td>\n",
              "      <td>[MIF, IFS, FST, STF, TFE, FEH, EHI, HIL, ILT, ...</td>\n",
              "      <td>[[3.6713390350341797, -1.519235372543335, 1.73...</td>\n",
              "      <td>[[-0.05383969098329544, 3.2187211513519287, 3....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q9LIK0</td>\n",
              "      <td>MSQSIQFSTPSHTPHLLHLPHSQFNRPLSSISFRRFPLTTIKYTSI...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>596</td>\n",
              "      <td>[MS, SQ, QS, SI, IQ, QF, FS, ST, TP, PS, SH, H...</td>\n",
              "      <td>[MSQ, SQS, QSI, SIQ, IQF, QFS, FST, STP, TPS, ...</td>\n",
              "      <td>[[4.511941909790039, 2.8832974433898926, 4.775...</td>\n",
              "      <td>[[5.155067443847656, 2.263141632080078, 0.8659...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q41643</td>\n",
              "      <td>MALAQKVASRPAVASRRGVVVVRASVESRRAVLGGLLASTVVALTS...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>202</td>\n",
              "      <td>[MA, AL, LA, AQ, QK, KV, VA, AS, SR, RP, PA, A...</td>\n",
              "      <td>[MAL, ALA, LAQ, AQK, QKV, KVA, VAS, ASR, SRP, ...</td>\n",
              "      <td>[[4.776439666748047, -0.9417923092842102, 1.21...</td>\n",
              "      <td>[[-0.6023486256599426, 2.5662193298339844, -1....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q8WHX1</td>\n",
              "      <td>MIGRLYMKKLKNLFLFLSSLCPVFPWISQISLVMPFGLYYGFLTAL...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1703</td>\n",
              "      <td>[MI, IG, GR, RL, LY, YM, MK, KK, KL, LK, KN, N...</td>\n",
              "      <td>[MIG, IGR, GRL, RLY, LYM, YMK, MKK, KKL, KLK, ...</td>\n",
              "      <td>[[3.6713390350341797, -1.519235372543335, 1.73...</td>\n",
              "      <td>[[-0.58070307970047, 4.1089677810668945, 0.724...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O19901</td>\n",
              "      <td>MEQYILKLENSINILAFLGALVSSLFYWAKLTYYKQIQVFSLPKFC...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>293</td>\n",
              "      <td>[ME, EQ, QY, YI, IL, LK, KL, LE, EN, NS, SI, I...</td>\n",
              "      <td>[MEQ, EQY, QYI, YIL, ILK, LKL, KLE, LEN, ENS, ...</td>\n",
              "      <td>[[-2.8613219261169434, -3.748929262161255, -2....</td>\n",
              "      <td>[[2.1231138706207275, 0.5452377796173096, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>573</th>\n",
              "      <td>O82245</td>\n",
              "      <td>MDSQDIRYRGGDDRDAATTAMAETERKSADDNKGKRDQKRAMAKRG...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>196</td>\n",
              "      <td>[MD, DS, SQ, QD, DI, IR, RY, YR, RG, GG, GD, D...</td>\n",
              "      <td>[MDS, DSQ, SQD, QDI, DIR, IRY, RYR, YRG, RGG, ...</td>\n",
              "      <td>[[1.7599092721939087, -7.816937446594238, 10.9...</td>\n",
              "      <td>[[0.3240453898906708, -0.06046273186802864, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>574</th>\n",
              "      <td>P54150</td>\n",
              "      <td>MQVLVVSPPLIAAASLSKPLNSLSKAALSFSRAKPICPFPQTSRRP...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>258</td>\n",
              "      <td>[MQ, QV, VL, LV, VV, VS, SP, PP, PL, LI, IA, A...</td>\n",
              "      <td>[MQV, QVL, VLV, LVV, VVS, VSP, SPP, PPL, PLI, ...</td>\n",
              "      <td>[[5.61092472076416, -0.2349075824022293, -2.81...</td>\n",
              "      <td>[[2.8016645908355713, 0.9308634996414185, -0.2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>Q42687</td>\n",
              "      <td>MLAAKSIAGPRAFKASAVRAAPKAGRRTVVVMARKNEVSESYAKAL...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>219</td>\n",
              "      <td>[ML, LA, AA, AK, KS, SI, IA, AG, GP, PR, RA, A...</td>\n",
              "      <td>[MLA, LAA, AAK, AKS, KSI, SIA, IAG, AGP, GPR, ...</td>\n",
              "      <td>[[2.7206990718841553, 1.4066028594970703, 1.40...</td>\n",
              "      <td>[[1.0453708171844482, 2.331393003463745, 2.178...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>Q949U7</td>\n",
              "      <td>MATSLSVSRFMSSSATVISVAKPLLSPTVSFTAPLSFTRSLAPNLS...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>234</td>\n",
              "      <td>[MA, AT, TS, SL, LS, SV, VS, SR, RF, FM, MS, S...</td>\n",
              "      <td>[MAT, ATS, TSL, SLS, LSV, SVS, VSR, SRF, RFM, ...</td>\n",
              "      <td>[[4.776439666748047, -0.9417923092842102, 1.21...</td>\n",
              "      <td>[[-1.428457260131836, -2.30820369720459, 1.542...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577</th>\n",
              "      <td>Q9FZ89</td>\n",
              "      <td>MGFVLICTCPPSSGVVVSQLHHHQFSAGVKSNELWFRPTRRTLISK...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>123</td>\n",
              "      <td>[MG, GF, FV, VL, LI, IC, CT, TC, CP, PP, PS, S...</td>\n",
              "      <td>[MGF, GFV, FVL, VLI, LIC, ICT, CTC, TCP, CPP, ...</td>\n",
              "      <td>[[-3.3130717277526855, -7.55003023147583, -2.4...</td>\n",
              "      <td>[[-0.39846715331077576, 2.371917247772217, 1.4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>578 rows Ã— 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f93e24c8-6f55-4259-a033-6b2a6b4aa1eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f93e24c8-6f55-4259-a033-6b2a6b4aa1eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f93e24c8-6f55-4259-a033-6b2a6b4aa1eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6beb50a7-0be2-4da5-9206-cb45aebd7490\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6beb50a7-0be2-4da5-9206-cb45aebd7490')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6beb50a7-0be2-4da5-9206-cb45aebd7490 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      PDBid                                           Sequence  envelope  \\\n",
              "0    Q2QD41  MIFSTFEHILTHISFSVISIVITIQLITLLINETVGLYVSSEKGMI...         0   \n",
              "1    Q9LIK0  MSQSIQFSTPSHTPHLLHLPHSQFNRPLSSISFRRFPLTTIKYTSI...         0   \n",
              "2    Q41643  MALAQKVASRPAVASRRGVVVVRASVESRRAVLGGLLASTVVALTS...         0   \n",
              "3    Q8WHX1  MIGRLYMKKLKNLFLFLSSLCPVFPWISQISLVMPFGLYYGFLTAL...         1   \n",
              "4    O19901  MEQYILKLENSINILAFLGALVSSLFYWAKLTYYKQIQVFSLPKFC...         0   \n",
              "..      ...                                                ...       ...   \n",
              "573  O82245  MDSQDIRYRGGDDRDAATTAMAETERKSADDNKGKRDQKRAMAKRG...         1   \n",
              "574  P54150  MQVLVVSPPLIAAASLSKPLNSLSKAALSFSRAKPICPFPQTSRRP...         0   \n",
              "575  Q42687  MLAAKSIAGPRAFKASAVRAAPKAGRRTVVVMARKNEVSESYAKAL...         0   \n",
              "576  Q949U7  MATSLSVSRFMSSSATVISVAKPLLSPTVSFTAPLSFTRSLAPNLS...         0   \n",
              "577  Q9FZ89  MGFVLICTCPPSSGVVVSQLHHHQFSAGVKSNELWFRPTRRTLISK...         0   \n",
              "\n",
              "     lumen  plastoglobule  stroma  thylakoid_membrane  Sum  Length  \\\n",
              "0        0              0       0                   1    1     323   \n",
              "1        0              0       1                   0    1     596   \n",
              "2        0              0       0                   1    1     202   \n",
              "3        0              0       0                   0    1    1703   \n",
              "4        0              0       0                   1    1     293   \n",
              "..     ...            ...     ...                 ...  ...     ...   \n",
              "573      0              0       0                   0    1     196   \n",
              "574      0              0       1                   0    1     258   \n",
              "575      0              0       0                   1    1     219   \n",
              "576      0              0       1                   0    1     234   \n",
              "577      0              1       0                   0    1     123   \n",
              "\n",
              "                                              Bi-grams  \\\n",
              "0    [MI, IF, FS, ST, TF, FE, EH, HI, IL, LT, TH, H...   \n",
              "1    [MS, SQ, QS, SI, IQ, QF, FS, ST, TP, PS, SH, H...   \n",
              "2    [MA, AL, LA, AQ, QK, KV, VA, AS, SR, RP, PA, A...   \n",
              "3    [MI, IG, GR, RL, LY, YM, MK, KK, KL, LK, KN, N...   \n",
              "4    [ME, EQ, QY, YI, IL, LK, KL, LE, EN, NS, SI, I...   \n",
              "..                                                 ...   \n",
              "573  [MD, DS, SQ, QD, DI, IR, RY, YR, RG, GG, GD, D...   \n",
              "574  [MQ, QV, VL, LV, VV, VS, SP, PP, PL, LI, IA, A...   \n",
              "575  [ML, LA, AA, AK, KS, SI, IA, AG, GP, PR, RA, A...   \n",
              "576  [MA, AT, TS, SL, LS, SV, VS, SR, RF, FM, MS, S...   \n",
              "577  [MG, GF, FV, VL, LI, IC, CT, TC, CP, PP, PS, S...   \n",
              "\n",
              "                                             Tri-grams  \\\n",
              "0    [MIF, IFS, FST, STF, TFE, FEH, EHI, HIL, ILT, ...   \n",
              "1    [MSQ, SQS, QSI, SIQ, IQF, QFS, FST, STP, TPS, ...   \n",
              "2    [MAL, ALA, LAQ, AQK, QKV, KVA, VAS, ASR, SRP, ...   \n",
              "3    [MIG, IGR, GRL, RLY, LYM, YMK, MKK, KKL, KLK, ...   \n",
              "4    [MEQ, EQY, QYI, YIL, ILK, LKL, KLE, LEN, ENS, ...   \n",
              "..                                                 ...   \n",
              "573  [MDS, DSQ, SQD, QDI, DIR, IRY, RYR, YRG, RGG, ...   \n",
              "574  [MQV, QVL, VLV, LVV, VVS, VSP, SPP, PPL, PLI, ...   \n",
              "575  [MLA, LAA, AAK, AKS, KSI, SIA, IAG, AGP, GPR, ...   \n",
              "576  [MAT, ATS, TSL, SLS, LSV, SVS, VSR, SRF, RFM, ...   \n",
              "577  [MGF, GFV, FVL, VLI, LIC, ICT, CTC, TCP, CPP, ...   \n",
              "\n",
              "                                             Bi-embeds  \\\n",
              "0    [[3.6713390350341797, -1.519235372543335, 1.73...   \n",
              "1    [[4.511941909790039, 2.8832974433898926, 4.775...   \n",
              "2    [[4.776439666748047, -0.9417923092842102, 1.21...   \n",
              "3    [[3.6713390350341797, -1.519235372543335, 1.73...   \n",
              "4    [[-2.8613219261169434, -3.748929262161255, -2....   \n",
              "..                                                 ...   \n",
              "573  [[1.7599092721939087, -7.816937446594238, 10.9...   \n",
              "574  [[5.61092472076416, -0.2349075824022293, -2.81...   \n",
              "575  [[2.7206990718841553, 1.4066028594970703, 1.40...   \n",
              "576  [[4.776439666748047, -0.9417923092842102, 1.21...   \n",
              "577  [[-3.3130717277526855, -7.55003023147583, -2.4...   \n",
              "\n",
              "                                            Tri-embeds  \n",
              "0    [[-0.05383969098329544, 3.2187211513519287, 3....  \n",
              "1    [[5.155067443847656, 2.263141632080078, 0.8659...  \n",
              "2    [[-0.6023486256599426, 2.5662193298339844, -1....  \n",
              "3    [[-0.58070307970047, 4.1089677810668945, 0.724...  \n",
              "4    [[2.1231138706207275, 0.5452377796173096, -0.0...  \n",
              "..                                                 ...  \n",
              "573  [[0.3240453898906708, -0.06046273186802864, 0....  \n",
              "574  [[2.8016645908355713, 0.9308634996414185, -0.2...  \n",
              "575  [[1.0453708171844482, 2.331393003463745, 2.178...  \n",
              "576  [[-1.428457260131836, -2.30820369720459, 1.542...  \n",
              "577  [[-0.39846715331077576, 2.371917247772217, 1.4...  \n",
              "\n",
              "[578 rows x 13 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', 50)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJGKVox1uXz9",
        "outputId": "b919ca6c-f5a1-4c92-8387-7cb23a9c5550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns containing zero-filled tokens:\n"
          ]
        }
      ],
      "source": [
        "# Function to check if a list of embeddings contains all zeros\n",
        "def embeddings_contain_all_zeros(embeddings_list):\n",
        "    for embedding in embeddings_list:\n",
        "        if all(val == 0.0 for val in embedding):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Check for zero-filled tokens in each column\n",
        "zero_filled_tokens = {}\n",
        "\n",
        "for column in df.columns:\n",
        "    if column.endswith('embeds'):  # Check if the column contains embeddings\n",
        "        zero_filled_tokens[column] = df[column].apply(embeddings_contain_all_zeros).any()\n",
        "\n",
        "# Print columns containing zero-filled tokens\n",
        "print(\"Columns containing zero-filled tokens:\")\n",
        "for column, contains_zero in zero_filled_tokens.items():\n",
        "    if contains_zero:\n",
        "        print(column)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb7VcvtJwxLG"
      },
      "source": [
        "## Feature Extraction using SXG on Word2Vec Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ICy-9gdwZi4"
      },
      "outputs": [],
      "source": [
        "def calculate_sxgbg_stan_features(evolutionary_profile, X):\n",
        "    L, _ = evolutionary_profile.shape\n",
        "    sxgbg_matrix = np.zeros((20, 20))\n",
        "\n",
        "    for i in range(20):\n",
        "        for j in range(20):\n",
        "            sxgbg_value = 0.0\n",
        "\n",
        "            for l in range(1, L - X):\n",
        "                sxgbg_value += evolutionary_profile[l - 1, i] * evolutionary_profile[l + X, j]\n",
        "\n",
        "            sxgbg_matrix[i, j] = sxgbg_value\n",
        "\n",
        "    # Standardize the sxgbg_matrix (z-score normalization)\n",
        "    mean = np.mean(sxgbg_matrix)\n",
        "    std = np.std(sxgbg_matrix)\n",
        "\n",
        "    if std != 0:\n",
        "        sxgbg_matrix = (sxgbg_matrix - mean) / std\n",
        "    else:\n",
        "        sxgbg_matrix = np.zeros_like(sxgbg_matrix)  # Handle the case of zero standard deviation\n",
        "\n",
        "    return sxgbg_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3xJdQE4eNBe"
      },
      "source": [
        "### SXG on Bi-gram Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHgNcz0EdA44"
      },
      "source": [
        "S0G on bi-gram embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c794cM1P-quX"
      },
      "outputs": [],
      "source": [
        "s0g_matrix_2g = []\n",
        "\n",
        "for i in df['Bi-embeds']:\n",
        "    s0g_mat_2g = calculate_sxgbg_stan_features(np.array(i), 0)\n",
        "    s0g_arr_2g = np.array(s0g_mat_2g)\n",
        "    s0g_matrix_2g.append(s0g_arr_2g)\n",
        "\n",
        "df['s0g_matrix_2g'] = s0g_matrix_2g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XBqkJ-RdWW1"
      },
      "source": [
        "S1G on bi-gram embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTUzn6xRdIM2"
      },
      "outputs": [],
      "source": [
        "s1g_matrix_2g = []\n",
        "\n",
        "for i in df['Bi-embeds']:\n",
        "    s1g_mat_2g = calculate_sxgbg_stan_features(np.array(i), 1)\n",
        "    s1g_arr_2g = np.array(s1g_mat_2g)\n",
        "    s1g_matrix_2g.append(s1g_arr_2g)\n",
        "\n",
        "df['s1g_matrix_2g'] = s1g_matrix_2g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3ZncOUQdjml"
      },
      "source": [
        "S2G on bi-gram embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5T4K-T-gdibm"
      },
      "outputs": [],
      "source": [
        "s2g_matrix_2g = []\n",
        "\n",
        "for i in df['Bi-embeds']:\n",
        "    s2g_mat_2g = calculate_sxgbg_stan_features(np.array(i), 2)\n",
        "    s2g_arr_2g = np.array(s2g_mat_2g)\n",
        "    s2g_matrix_2g.append(s2g_arr_2g)\n",
        "\n",
        "df['s2g_matrix_2g'] = s2g_matrix_2g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP6TpQR3d1rZ"
      },
      "source": [
        "S3G on bi-gram embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsEavro0duJM"
      },
      "outputs": [],
      "source": [
        "s3g_matrix_2g = []\n",
        "\n",
        "for i in df['Bi-embeds']:\n",
        "    s3g_mat_2g = calculate_sxgbg_stan_features(np.array(i), 3)\n",
        "    s3g_arr_2g = np.array(s3g_mat_2g)\n",
        "    s3g_matrix_2g.append(s3g_arr_2g)\n",
        "\n",
        "df['s3g_matrix_2g'] = s3g_matrix_2g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqjGOCqbd-5p"
      },
      "source": [
        "S4G on bi-gram embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuO58vnpd-BB"
      },
      "outputs": [],
      "source": [
        "s4g_matrix_2g = []\n",
        "\n",
        "for i in df['Bi-embeds']:\n",
        "    s4g_mat_2g = calculate_sxgbg_stan_features(np.array(i), 4)\n",
        "    s4g_arr_2g = np.array(s4g_mat_2g)\n",
        "    s4g_matrix_2g.append(s4g_arr_2g)\n",
        "\n",
        "df['s4g_matrix_2g'] = s4g_matrix_2g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COk1-TZ3eIbx"
      },
      "source": [
        "### SXG on Tri-gram embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bm9RA43edQt"
      },
      "source": [
        "S0G on Tri-gram embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSfTXVVzeH80"
      },
      "outputs": [],
      "source": [
        "s0g_matrix_3gram = []\n",
        "\n",
        "for i in df['Tri-embeds']:\n",
        "    s0g_mat_3 = calculate_sxgbg_stan_features(np.array(i), 0)\n",
        "    s0g_arr_3 = np.array(s0g_mat_3)\n",
        "    s0g_matrix_3gram.append(s0g_arr_3)\n",
        "\n",
        "df['s0g_matrix_3gram'] = s0g_matrix_3gram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYOyhMYHenqn"
      },
      "source": [
        "S1G on Tri-gram embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlrJbs2OemL5"
      },
      "outputs": [],
      "source": [
        "s1g_matrix_3gram = []\n",
        "\n",
        "for i in df['Tri-embeds']:\n",
        "    s1g_mat_3 = calculate_sxgbg_stan_features(np.array(i), 1)\n",
        "    s1g_arr_3 = np.array(s1g_mat_3)\n",
        "    s1g_matrix_3gram.append(s1g_arr_3)\n",
        "\n",
        "df['s1g_matrix_3gram'] = s1g_matrix_3gram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiFtEJ3beueO"
      },
      "source": [
        "S2G on Tri-gram embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1P1rfomzexgJ"
      },
      "outputs": [],
      "source": [
        "s2g_matrix_3gram = []\n",
        "\n",
        "for i in df['Tri-embeds']:\n",
        "    s2g_mat_3 = calculate_sxgbg_stan_features(np.array(i), 2)\n",
        "    s2g_arr_3 = np.array(s2g_mat_3)\n",
        "    s2g_matrix_3gram.append(s2g_arr_3)\n",
        "\n",
        "df['s2g_matrix_3gram'] = s2g_matrix_3gram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCY8RmSRfMFP"
      },
      "source": [
        "## Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nm2Quh8RfONL"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(y_true, y_pred):\n",
        "    # Ensure inputs are numpy arrays\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array((y_pred>0.5).astype(int))\n",
        "\n",
        "    # Initialize accuracy\n",
        "    accuracy = 0\n",
        "\n",
        "    # Calculate accuracy for each instance\n",
        "    for i in range(len(y_true)):\n",
        "        # Calculate intersection and union\n",
        "        intersection = np.sum(np.logical_and(y_true[i], y_pred[i]))\n",
        "        union = np.sum(np.logical_or(y_true[i], y_pred[i]))\n",
        "\n",
        "        # Add to total accuracy\n",
        "        accuracy += intersection / union\n",
        "\n",
        "    # Calculate average accuracy\n",
        "    accuracy /= len(y_true)\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blxl46asfY2X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def norm_accuracy(y_true, y_pred):\n",
        "    # Ensure inputs are numpy arrays\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array((y_pred>0.5).astype(int))\n",
        "\n",
        "    acc = []\n",
        "    # Loop over each instance\n",
        "    for i in range(len(y_true)):\n",
        "        # Calculate the number of correct predictions for this instance\n",
        "        correct_predictions = np.sum(y_true[i] == y_pred[i])\n",
        "        acc.append(correct_predictions/5)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = sum(acc) / len(y_true)\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9wFun3nfbIE"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNf7VYVdfcFE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyAugqpIggrz"
      },
      "source": [
        "### s0g_matrix_2g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qypb-Gn6gN7-",
        "outputId": "2834600f-71fe-4950-fded-97633c03cc0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 5s 6ms/step - loss: 0.5019 - accuracy: 0.3831 - val_loss: 0.4305 - val_accuracy: 0.4224 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.4353 - accuracy: 0.4459 - val_loss: 0.3656 - val_accuracy: 0.5172 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.4009 - accuracy: 0.5022 - val_loss: 0.3719 - val_accuracy: 0.4828 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.3804 - accuracy: 0.5390 - val_loss: 0.3650 - val_accuracy: 0.5517 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.3485 - accuracy: 0.5736 - val_loss: 0.4103 - val_accuracy: 0.4828 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.3167 - accuracy: 0.6212 - val_loss: 0.3613 - val_accuracy: 0.6121 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.2931 - accuracy: 0.6645 - val_loss: 0.3436 - val_accuracy: 0.6293 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.2786 - accuracy: 0.6905 - val_loss: 0.3543 - val_accuracy: 0.5948 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.2580 - accuracy: 0.7381 - val_loss: 0.3857 - val_accuracy: 0.6207 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.2123 - accuracy: 0.7860\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.2121 - accuracy: 0.7857 - val_loss: 0.4335 - val_accuracy: 0.5776 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1634 - accuracy: 0.8355 - val_loss: 0.4205 - val_accuracy: 0.5862 - lr: 5.0000e-04\n",
            "Epoch 12/15\n",
            "221/231 [===========================>..] - ETA: 0s - loss: 0.1279 - accuracy: 0.8710Restoring model weights from the end of the best epoch: 7.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1303 - accuracy: 0.8680 - val_loss: 0.4292 - val_accuracy: 0.5948 - lr: 5.0000e-04\n",
            "Epoch 12: early stopping\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "231/231 [==============================] - 3s 5ms/step - loss: 0.3101 - accuracy: 0.6515 - val_loss: 0.2429 - val_accuracy: 0.7155 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.2606 - accuracy: 0.7035 - val_loss: 0.2320 - val_accuracy: 0.7155 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.2408 - accuracy: 0.7316 - val_loss: 0.2723 - val_accuracy: 0.6897 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.2250 - accuracy: 0.7576\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.2269 - accuracy: 0.7532 - val_loss: 0.2844 - val_accuracy: 0.6638 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1788 - accuracy: 0.8117 - val_loss: 0.2323 - val_accuracy: 0.7672 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1499 - accuracy: 0.8528 - val_loss: 0.2459 - val_accuracy: 0.7241 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1307 - accuracy: 0.8701 - val_loss: 0.2425 - val_accuracy: 0.7069 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.1181 - accuracy: 0.8843\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1174 - accuracy: 0.8853 - val_loss: 0.2529 - val_accuracy: 0.7241 - lr: 5.0000e-04\n",
            "Epoch 9/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0937 - accuracy: 0.9134 - val_loss: 0.2394 - val_accuracy: 0.7759 - lr: 2.5000e-04\n",
            "Epoch 10/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0856 - accuracy: 0.9242 - val_loss: 0.2523 - val_accuracy: 0.7414 - lr: 2.5000e-04\n",
            "Epoch 11/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0714 - accuracy: 0.9394 - val_loss: 0.2629 - val_accuracy: 0.7586 - lr: 2.5000e-04\n",
            "Epoch 12/15\n",
            "226/231 [============================>.] - ETA: 0s - loss: 0.0687 - accuracy: 0.9403\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.0683 - accuracy: 0.9416 - val_loss: 0.2521 - val_accuracy: 0.7759 - lr: 2.5000e-04\n",
            "Epoch 13/15\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.0560 - accuracy: 0.9524 - val_loss: 0.2728 - val_accuracy: 0.7672 - lr: 1.2500e-04\n",
            "Epoch 14/15\n",
            "224/231 [============================>.] - ETA: 0s - loss: 0.0521 - accuracy: 0.9531Restoring model weights from the end of the best epoch: 9.\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.0535 - accuracy: 0.9545 - val_loss: 0.3040 - val_accuracy: 0.7328 - lr: 1.2500e-04\n",
            "Epoch 14: early stopping\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "231/231 [==============================] - 2s 5ms/step - loss: 0.1796 - accuracy: 0.8182 - val_loss: 0.1220 - val_accuracy: 0.9138 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1422 - accuracy: 0.8571 - val_loss: 0.1150 - val_accuracy: 0.9224 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.1257 - accuracy: 0.8831 - val_loss: 0.1180 - val_accuracy: 0.8793 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0932 - accuracy: 0.9156 - val_loss: 0.1023 - val_accuracy: 0.8966 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "224/231 [============================>.] - ETA: 0s - loss: 0.0945 - accuracy: 0.9085\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.0943 - accuracy: 0.9091 - val_loss: 0.1538 - val_accuracy: 0.8276 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0588 - accuracy: 0.9502 - val_loss: 0.1215 - val_accuracy: 0.8621 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "221/231 [===========================>..] - ETA: 0s - loss: 0.0337 - accuracy: 0.9774Restoring model weights from the end of the best epoch: 2.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0365 - accuracy: 0.9740 - val_loss: 0.1002 - val_accuracy: 0.9224 - lr: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "232/232 [==============================] - 3s 6ms/step - loss: 0.1636 - accuracy: 0.8467 - val_loss: 0.1059 - val_accuracy: 0.9304 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.1310 - accuracy: 0.8769 - val_loss: 0.1435 - val_accuracy: 0.8783 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.1124 - accuracy: 0.8898 - val_loss: 0.0892 - val_accuracy: 0.9217 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "224/232 [===========================>..] - ETA: 0s - loss: 0.1131 - accuracy: 0.8772\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.1119 - accuracy: 0.8769 - val_loss: 0.1127 - val_accuracy: 0.9304 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0628 - accuracy: 0.9417 - val_loss: 0.0829 - val_accuracy: 0.9304 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0423 - accuracy: 0.9633 - val_loss: 0.0678 - val_accuracy: 0.9478 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "232/232 [==============================] - 2s 7ms/step - loss: 0.0318 - accuracy: 0.9698 - val_loss: 0.0682 - val_accuracy: 0.9652 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "232/232 [==============================] - 1s 6ms/step - loss: 0.0363 - accuracy: 0.9741 - val_loss: 0.0764 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
            "Epoch 9/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9698 - val_loss: 0.0730 - val_accuracy: 0.9652 - lr: 5.0000e-04\n",
            "Epoch 10/15\n",
            "221/232 [===========================>..] - ETA: 0s - loss: 0.0301 - accuracy: 0.9661\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0311 - accuracy: 0.9654 - val_loss: 0.0856 - val_accuracy: 0.9304 - lr: 5.0000e-04\n",
            "Epoch 11/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0192 - accuracy: 0.9698 - val_loss: 0.0932 - val_accuracy: 0.9217 - lr: 2.5000e-04\n",
            "Epoch 12/15\n",
            "225/232 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9756Restoring model weights from the end of the best epoch: 7.\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0140 - accuracy: 0.9741 - val_loss: 0.0970 - val_accuracy: 0.9217 - lr: 2.5000e-04\n",
            "Epoch 12: early stopping\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "232/232 [==============================] - 2s 5ms/step - loss: 0.1030 - accuracy: 0.9050 - val_loss: 0.1179 - val_accuracy: 0.8870 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0716 - accuracy: 0.9438 - val_loss: 0.1057 - val_accuracy: 0.8783 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.1118 - accuracy: 0.9114 - val_loss: 0.1151 - val_accuracy: 0.8870 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "225/232 [============================>.] - ETA: 0s - loss: 0.0687 - accuracy: 0.9311\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0701 - accuracy: 0.9309 - val_loss: 0.0859 - val_accuracy: 0.8870 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "232/232 [==============================] - 2s 6ms/step - loss: 0.0454 - accuracy: 0.9654 - val_loss: 0.0605 - val_accuracy: 0.9304 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "232/232 [==============================] - 1s 6ms/step - loss: 0.0231 - accuracy: 0.9849 - val_loss: 0.0608 - val_accuracy: 0.9217 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0182 - accuracy: 0.9762 - val_loss: 0.0543 - val_accuracy: 0.9304 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "229/232 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9694\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0147 - accuracy: 0.9698 - val_loss: 0.0604 - val_accuracy: 0.9304 - lr: 5.0000e-04\n",
            "Epoch 9/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0189 - accuracy: 0.9806 - val_loss: 0.0645 - val_accuracy: 0.9217 - lr: 2.5000e-04\n",
            "Epoch 10/15\n",
            "221/232 [===========================>..] - ETA: 0s - loss: 0.0153 - accuracy: 0.9796Restoring model weights from the end of the best epoch: 5.\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0147 - accuracy: 0.9806 - val_loss: 0.0576 - val_accuracy: 0.9304 - lr: 2.5000e-04\n",
            "Epoch 10: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Average Accuracy:  0.7686506746626687\n",
            "Accuracy:  0.9378500749625183\n",
            "Average Normalized Accuracy:  0.7888505747126436\n",
            "Average Precision:  0.8795186806083528\n",
            "Average Recall:  0.7812438502370028\n",
            "F1 score: 0.8274735823237577\n",
            "Grand Mean: 0.8305979062511573\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "model_s0g = keras.Sequential([\n",
        "    keras.layers.Input(shape=(None, 400)),\n",
        "    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(5, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Load your data and preprocess it\n",
        "train_features = np.array(df['s0g_matrix_2g'].tolist())\n",
        "train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n",
        "\n",
        "train_features = train_features.reshape(-1, 400)\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "# Initialize a list to store accuracy scores\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "acc_scores = []\n",
        "acc_norm = []\n",
        "\n",
        "# Iterate over each sample for LOOCV\n",
        "for train_index, test_index in kf.split(train_features):\n",
        "    X_train, X_test = train_features[train_index], train_features[test_index]\n",
        "    y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
        "\n",
        "    # Compile the model and set up callbacks (as in your code)\n",
        "    model_s0g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=5, verbose=1, restore_best_weights=True)\n",
        "    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "    callbacks = [early_stopping, lr_scheduler]\n",
        "\n",
        "    batch_size = 2\n",
        "    model_s0g.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "    # Make predictions on the current test sample\n",
        "    y_pred = model_s0g.predict(X_test)\n",
        "\n",
        "\n",
        "    # Calculate and store the accuracy for this fold\n",
        "    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
        "    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    acc_scores.append(norm_accuracy(y_test, y_pred))\n",
        "    acc_norm.append(calculate_accuracy(y_test, y_pred))\n",
        "\n",
        "# Calculate the average accuracy across all folds\n",
        "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "avg_precision = sum(precision_scores) / len(precision_scores)\n",
        "avg_acc_norm = sum(acc_norm)/len(acc_norm)\n",
        "avg_recall = sum(recall_scores) / len(recall_scores)\n",
        "avg_acc = sum(acc_scores)/len(acc_scores)\n",
        "f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
        "grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n",
        "# Print the average accuracy\n",
        "print(\"Average Accuracy: \", average_accuracy)\n",
        "print(\"Accuracy: \", avg_acc)\n",
        "print(\"Average Normalized Accuracy: \", avg_acc_norm)\n",
        "print(\"Average Precision: \", avg_precision)\n",
        "print(\"Average Recall: \", avg_recall)\n",
        "print('F1 score:', f1)\n",
        "print('Grand Mean:', grand_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jssuGBYhh4Y1"
      },
      "source": [
        "### s1g_matrix_2g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "PRyn4EW6gqKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49e6373-f9a0-4999-f825-5f1bc3447f81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 7s 14ms/step - loss: 0.5289 - accuracy: 0.3745 - val_loss: 0.4454 - val_accuracy: 0.4483 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.3364 - accuracy: 0.6385 - val_loss: 0.4693 - val_accuracy: 0.4483 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1953 - accuracy: 0.8225 - val_loss: 0.5112 - val_accuracy: 0.4828 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1259 - accuracy: 0.9113 - val_loss: 0.6424 - val_accuracy: 0.4310 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0928 - accuracy: 0.9264 - val_loss: 0.6542 - val_accuracy: 0.4655 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "222/231 [===========================>..] - ETA: 0s - loss: 0.0629 - accuracy: 0.9505\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0652 - accuracy: 0.9502 - val_loss: 0.8202 - val_accuracy: 0.3879 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0337 - accuracy: 0.9740 - val_loss: 0.8545 - val_accuracy: 0.4224 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "225/231 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9778Restoring model weights from the end of the best epoch: 3.\n",
            "231/231 [==============================] - 2s 10ms/step - loss: 0.0222 - accuracy: 0.9784 - val_loss: 0.8483 - val_accuracy: 0.4224 - lr: 5.0000e-04\n",
            "Epoch 8: early stopping\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "231/231 [==============================] - 3s 5ms/step - loss: 0.2553 - accuracy: 0.7835 - val_loss: 0.1341 - val_accuracy: 0.8879 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1231 - accuracy: 0.8874 - val_loss: 0.1483 - val_accuracy: 0.8534 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0706 - accuracy: 0.9502 - val_loss: 0.1772 - val_accuracy: 0.8276 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9632\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.0469 - accuracy: 0.9632 - val_loss: 0.2160 - val_accuracy: 0.7586 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0253 - accuracy: 0.9762 - val_loss: 0.1901 - val_accuracy: 0.8190 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "215/231 [==========================>...] - ETA: 0s - loss: 0.0182 - accuracy: 0.9814Restoring model weights from the end of the best epoch: 1.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0186 - accuracy: 0.9784 - val_loss: 0.1923 - val_accuracy: 0.8190 - lr: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "231/231 [==============================] - 3s 7ms/step - loss: 0.1532 - accuracy: 0.8463 - val_loss: 0.1296 - val_accuracy: 0.8966 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.0912 - accuracy: 0.9199 - val_loss: 0.1540 - val_accuracy: 0.8707 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0552 - accuracy: 0.9632 - val_loss: 0.1831 - val_accuracy: 0.8534 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "221/231 [===========================>..] - ETA: 0s - loss: 0.0546 - accuracy: 0.9638\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0547 - accuracy: 0.9632 - val_loss: 0.2256 - val_accuracy: 0.7931 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9848 - val_loss: 0.2115 - val_accuracy: 0.8103 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "221/231 [===========================>..] - ETA: 0s - loss: 0.0114 - accuracy: 0.9842Restoring model weights from the end of the best epoch: 1.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.9848 - val_loss: 0.2422 - val_accuracy: 0.7845 - lr: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "232/232 [==============================] - 2s 5ms/step - loss: 0.1286 - accuracy: 0.8920 - val_loss: 0.0573 - val_accuracy: 0.9739 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 2s 7ms/step - loss: 0.0647 - accuracy: 0.9525 - val_loss: 0.0653 - val_accuracy: 0.9652 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 2s 7ms/step - loss: 0.0465 - accuracy: 0.9633 - val_loss: 0.0513 - val_accuracy: 0.9913 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0357 - accuracy: 0.9654 - val_loss: 0.0584 - val_accuracy: 0.9652 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0268 - accuracy: 0.9698 - val_loss: 0.0959 - val_accuracy: 0.9217 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "225/232 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9889\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0221 - accuracy: 0.9870 - val_loss: 0.1372 - val_accuracy: 0.8957 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0248 - accuracy: 0.9806 - val_loss: 0.1313 - val_accuracy: 0.8957 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "232/232 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9892Restoring model weights from the end of the best epoch: 3.\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.9892 - val_loss: 0.1247 - val_accuracy: 0.9130 - lr: 5.0000e-04\n",
            "Epoch 8: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "232/232 [==============================] - 2s 5ms/step - loss: 0.0689 - accuracy: 0.9352 - val_loss: 0.0262 - val_accuracy: 0.9913 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0423 - accuracy: 0.9633 - val_loss: 0.0234 - val_accuracy: 0.9826 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0308 - accuracy: 0.9892 - val_loss: 0.0292 - val_accuracy: 0.9826 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "228/232 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9737\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 1s 6ms/step - loss: 0.0243 - accuracy: 0.9741 - val_loss: 0.0325 - val_accuracy: 0.9739 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "232/232 [==============================] - 2s 7ms/step - loss: 0.0231 - accuracy: 0.9654 - val_loss: 0.0365 - val_accuracy: 0.9652 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "226/232 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9823Restoring model weights from the end of the best epoch: 1.\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.9806 - val_loss: 0.0346 - val_accuracy: 0.9739 - lr: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Average Accuracy:  0.7722188905547226\n",
            "Accuracy:  0.9361649175412291\n",
            "Average Normalized Accuracy:  0.7895152423788107\n",
            "Average Precision:  0.8613763702249522\n",
            "Average Recall:  0.78627860126062\n",
            "F1 score: 0.8221160610206747\n",
            "Grand Mean: 0.8279450138301683\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "model_s1g = keras.Sequential([\n",
        "    keras.layers.Input(shape=(None, 400)),\n",
        "    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(5, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Load your data and preprocess it\n",
        "train_features = np.array(df['s1g_matrix_2g'].tolist())\n",
        "train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n",
        "\n",
        "train_features = train_features.reshape(-1, 400)\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "# Initialize a list to store accuracy scores\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "acc_scores = []\n",
        "acc_norm = []\n",
        "\n",
        "# Iterate over each sample for LOOCV\n",
        "for train_index, test_index in kf.split(train_features):\n",
        "    X_train, X_test = train_features[train_index], train_features[test_index]\n",
        "    y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
        "\n",
        "    # Compile the model and set up callbacks (as in your code)\n",
        "    model_s1g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=5, verbose=1, restore_best_weights=True)\n",
        "    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "    callbacks = [early_stopping, lr_scheduler]\n",
        "\n",
        "    batch_size = 2\n",
        "    model_s1g.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "    # Make predictions on the current test sample\n",
        "    y_pred = model_s1g.predict(X_test)\n",
        "\n",
        "\n",
        "    # Calculate and store the accuracy for this fold\n",
        "    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
        "    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    acc_scores.append(norm_accuracy(y_test, y_pred))\n",
        "    acc_norm.append(calculate_accuracy(y_test, y_pred))\n",
        "\n",
        "# Calculate the average accuracy across all folds\n",
        "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "avg_precision = sum(precision_scores) / len(precision_scores)\n",
        "avg_acc_norm = sum(acc_norm)/len(acc_norm)\n",
        "avg_recall = sum(recall_scores) / len(recall_scores)\n",
        "avg_acc = sum(acc_scores)/len(acc_scores)\n",
        "f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
        "grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n",
        "# Print the average accuracy\n",
        "print(\"Average Accuracy: \", average_accuracy)\n",
        "print(\"Accuracy: \", avg_acc)\n",
        "print(\"Average Normalized Accuracy: \", avg_acc_norm)\n",
        "print(\"Average Precision: \", avg_precision)\n",
        "print(\"Average Recall: \", avg_recall)\n",
        "print('F1 score:', f1)\n",
        "print('Grand Mean:', grand_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtAu9vG1i9qD"
      },
      "source": [
        "### s2g_matrix_2g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "e-g_hU4SjBZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2d1ce68-5df9-42e8-8065-96f79f181248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 3s 7ms/step - loss: 0.5040 - accuracy: 0.3593 - val_loss: 0.4279 - val_accuracy: 0.3879 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.3846 - accuracy: 0.5584 - val_loss: 0.4724 - val_accuracy: 0.3621 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.2732 - accuracy: 0.7013 - val_loss: 0.5156 - val_accuracy: 0.2931 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1704 - accuracy: 0.8268 - val_loss: 0.5642 - val_accuracy: 0.4224 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.1012 - accuracy: 0.9177 - val_loss: 0.7132 - val_accuracy: 0.3707 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0579 - accuracy: 0.9524 - val_loss: 0.8844 - val_accuracy: 0.3448 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "225/231 [============================>.] - ETA: 0s - loss: 0.0327 - accuracy: 0.9844\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0338 - accuracy: 0.9827 - val_loss: 0.9625 - val_accuracy: 0.3534 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0342 - accuracy: 0.9675 - val_loss: 0.8676 - val_accuracy: 0.4224 - lr: 5.0000e-04\n",
            "Epoch 9/15\n",
            "226/231 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9757Restoring model weights from the end of the best epoch: 4.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0168 - accuracy: 0.9762 - val_loss: 0.9004 - val_accuracy: 0.4052 - lr: 5.0000e-04\n",
            "Epoch 9: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "231/231 [==============================] - 2s 4ms/step - loss: 0.2297 - accuracy: 0.7749 - val_loss: 0.1207 - val_accuracy: 0.9138 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1015 - accuracy: 0.9264 - val_loss: 0.1131 - val_accuracy: 0.8966 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0562 - accuracy: 0.9524 - val_loss: 0.1257 - val_accuracy: 0.8621 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "224/231 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9643\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9654 - val_loss: 0.1794 - val_accuracy: 0.8448 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9762 - val_loss: 0.1804 - val_accuracy: 0.8190 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "225/231 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9800Restoring model weights from the end of the best epoch: 1.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0137 - accuracy: 0.9784 - val_loss: 0.1735 - val_accuracy: 0.8362 - lr: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "231/231 [==============================] - 3s 7ms/step - loss: 0.1493 - accuracy: 0.8615 - val_loss: 0.0589 - val_accuracy: 0.9310 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.0666 - accuracy: 0.9459 - val_loss: 0.0714 - val_accuracy: 0.9483 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0406 - accuracy: 0.9740 - val_loss: 0.0775 - val_accuracy: 0.9483 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0383 - accuracy: 0.9719 - val_loss: 0.0960 - val_accuracy: 0.9138 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9719\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0285 - accuracy: 0.9719 - val_loss: 0.1221 - val_accuracy: 0.8966 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0143 - accuracy: 0.9848 - val_loss: 0.1558 - val_accuracy: 0.8793 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9868Restoring model weights from the end of the best epoch: 2.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9870 - val_loss: 0.1332 - val_accuracy: 0.8793 - lr: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "232/232 [==============================] - 3s 6ms/step - loss: 0.0761 - accuracy: 0.9374 - val_loss: 0.0225 - val_accuracy: 0.9826 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 1s 6ms/step - loss: 0.0652 - accuracy: 0.9482 - val_loss: 0.0444 - val_accuracy: 0.9652 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 2s 7ms/step - loss: 0.0271 - accuracy: 0.9741 - val_loss: 0.0499 - val_accuracy: 0.9391 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "221/232 [===========================>..] - ETA: 0s - loss: 0.0259 - accuracy: 0.9842\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 1s 6ms/step - loss: 0.0255 - accuracy: 0.9849 - val_loss: 0.0722 - val_accuracy: 0.9304 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0178 - accuracy: 0.9633 - val_loss: 0.0802 - val_accuracy: 0.9478 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "229/232 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9847Restoring model weights from the end of the best epoch: 1.\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0154 - accuracy: 0.9827 - val_loss: 0.0603 - val_accuracy: 0.9478 - lr: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "232/232 [==============================] - 2s 5ms/step - loss: 0.0623 - accuracy: 0.9590 - val_loss: 0.0303 - val_accuracy: 0.9739 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0558 - accuracy: 0.9611 - val_loss: 0.0592 - val_accuracy: 0.9565 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0183 - accuracy: 0.9762 - val_loss: 0.0719 - val_accuracy: 0.9304 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "232/232 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9806\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0215 - accuracy: 0.9806 - val_loss: 0.0681 - val_accuracy: 0.9391 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9762 - val_loss: 0.0643 - val_accuracy: 0.9739 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "228/232 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9825Restoring model weights from the end of the best epoch: 1.\n",
            "232/232 [==============================] - 2s 7ms/step - loss: 0.0090 - accuracy: 0.9827 - val_loss: 0.0754 - val_accuracy: 0.9217 - lr: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Average Accuracy:  0.796416791604198\n",
            "Accuracy:  0.9392833583208391\n",
            "Average Normalized Accuracy:  0.8260844577711145\n",
            "Average Precision:  0.8373448079026838\n",
            "Average Recall:  0.8373896077189716\n",
            "F1 score: 0.8373672072116213\n",
            "Grand Mean: 0.845647705088238\n"
          ]
        }
      ],
      "source": [
        "model_s2g = keras.Sequential([\n",
        "    keras.layers.Input(shape=(None, 400)),\n",
        "    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(5, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Load your data and preprocess it\n",
        "train_features = np.array(df['s2g_matrix_2g'].tolist())\n",
        "train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n",
        "\n",
        "train_features = train_features.reshape(-1, 400)\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "# Initialize a list to store accuracy scores\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "acc_scores = []\n",
        "acc_norm = []\n",
        "\n",
        "# Iterate over each sample for LOOCV\n",
        "for train_index, test_index in kf.split(train_features):\n",
        "    X_train, X_test = train_features[train_index], train_features[test_index]\n",
        "    y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
        "\n",
        "    # Compile the model and set up callbacks (as in your code)\n",
        "    model_s2g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=5, verbose=1, restore_best_weights=True)\n",
        "    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "    callbacks = [early_stopping, lr_scheduler]\n",
        "\n",
        "    batch_size = 2\n",
        "    model_s2g.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "    # Make predictions on the current test sample\n",
        "    y_pred = model_s2g.predict(X_test)\n",
        "\n",
        "\n",
        "    # Calculate and store the accuracy for this fold\n",
        "    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
        "    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    acc_scores.append(norm_accuracy(y_test, y_pred))\n",
        "    acc_norm.append(calculate_accuracy(y_test, y_pred))\n",
        "\n",
        "# Calculate the average accuracy across all folds\n",
        "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "avg_precision = sum(precision_scores) / len(precision_scores)\n",
        "avg_acc_norm = sum(acc_norm)/len(acc_norm)\n",
        "avg_recall = sum(recall_scores) / len(recall_scores)\n",
        "avg_acc = sum(acc_scores)/len(acc_scores)\n",
        "f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
        "grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n",
        "# Print the average accuracy\n",
        "print(\"Average Accuracy: \", average_accuracy)\n",
        "print(\"Accuracy: \", avg_acc)\n",
        "print(\"Average Normalized Accuracy: \", avg_acc_norm)\n",
        "print(\"Average Precision: \", avg_precision)\n",
        "print(\"Average Recall: \", avg_recall)\n",
        "print('F1 score:', f1)\n",
        "print('Grand Mean:', grand_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKtQA7HgkQNE"
      },
      "source": [
        "### s3g_matrix_2g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF8UV0gZkVEr",
        "outputId": "e61f14ae-2491-45bc-b2fd-1b4ec67a5951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 2s 5ms/step - loss: 0.5224 - accuracy: 0.3658 - val_loss: 0.4095 - val_accuracy: 0.4741 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.3924 - accuracy: 0.5390 - val_loss: 0.4294 - val_accuracy: 0.4914 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.2658 - accuracy: 0.7165 - val_loss: 0.4921 - val_accuracy: 0.3966 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1757 - accuracy: 0.8355 - val_loss: 0.5345 - val_accuracy: 0.5172 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1016 - accuracy: 0.9113 - val_loss: 0.5741 - val_accuracy: 0.4914 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0684 - accuracy: 0.9416 - val_loss: 0.6380 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "219/231 [===========================>..] - ETA: 0s - loss: 0.0474 - accuracy: 0.9658\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0465 - accuracy: 0.9675 - val_loss: 0.7551 - val_accuracy: 0.4741 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - 2s 8ms/step - loss: 0.0358 - accuracy: 0.9675 - val_loss: 0.7120 - val_accuracy: 0.5172 - lr: 5.0000e-04\n",
            "Epoch 9/15\n",
            "223/231 [===========================>..] - ETA: 0s - loss: 0.0181 - accuracy: 0.9686Restoring model weights from the end of the best epoch: 4.\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0177 - accuracy: 0.9697 - val_loss: 0.8176 - val_accuracy: 0.4741 - lr: 5.0000e-04\n",
            "Epoch 9: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "231/231 [==============================] - 2s 5ms/step - loss: 0.2313 - accuracy: 0.7987 - val_loss: 0.1136 - val_accuracy: 0.9052 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1091 - accuracy: 0.9026 - val_loss: 0.1020 - val_accuracy: 0.9224 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0569 - accuracy: 0.9524 - val_loss: 0.1388 - val_accuracy: 0.8621 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0459 - accuracy: 0.9589 - val_loss: 0.1614 - val_accuracy: 0.8448 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "223/231 [===========================>..] - ETA: 0s - loss: 0.0381 - accuracy: 0.9686\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0373 - accuracy: 0.9654 - val_loss: 0.1754 - val_accuracy: 0.8190 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0389 - accuracy: 0.9610 - val_loss: 0.1630 - val_accuracy: 0.8190 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "221/231 [===========================>..] - ETA: 0s - loss: 0.0187 - accuracy: 0.9729Restoring model weights from the end of the best epoch: 2.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0182 - accuracy: 0.9740 - val_loss: 0.2016 - val_accuracy: 0.8276 - lr: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 1/15\n",
            "231/231 [==============================] - 3s 5ms/step - loss: 0.1050 - accuracy: 0.9113 - val_loss: 0.0686 - val_accuracy: 0.9310 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0558 - accuracy: 0.9632 - val_loss: 0.0503 - val_accuracy: 0.9397 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0426 - accuracy: 0.9632 - val_loss: 0.0463 - val_accuracy: 0.9397 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0403 - accuracy: 0.9567 - val_loss: 0.0610 - val_accuracy: 0.9483 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0257 - accuracy: 0.9762 - val_loss: 0.0880 - val_accuracy: 0.9310 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0287 - accuracy: 0.9848 - val_loss: 0.0841 - val_accuracy: 0.9052 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "226/231 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9735\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0140 - accuracy: 0.9740 - val_loss: 0.1001 - val_accuracy: 0.8621 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9827 - val_loss: 0.0920 - val_accuracy: 0.8707 - lr: 5.0000e-04\n",
            "Epoch 9/15\n",
            "227/231 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9824Restoring model weights from the end of the best epoch: 4.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9805 - val_loss: 0.0966 - val_accuracy: 0.8879 - lr: 5.0000e-04\n",
            "Epoch 9: early stopping\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 1/15\n",
            "232/232 [==============================] - 4s 8ms/step - loss: 0.0617 - accuracy: 0.9482 - val_loss: 0.0249 - val_accuracy: 0.9652 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0461 - accuracy: 0.9590 - val_loss: 0.0154 - val_accuracy: 0.9826 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0255 - accuracy: 0.9827 - val_loss: 0.0185 - val_accuracy: 0.9739 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9698 - val_loss: 0.0197 - val_accuracy: 0.9739 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "228/232 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9781\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9784 - val_loss: 0.0540 - val_accuracy: 0.9478 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0229 - accuracy: 0.9741 - val_loss: 0.0288 - val_accuracy: 0.9652 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "225/232 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9822Restoring model weights from the end of the best epoch: 2.\n",
            "232/232 [==============================] - 2s 8ms/step - loss: 0.0073 - accuracy: 0.9827 - val_loss: 0.0381 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "232/232 [==============================] - 2s 5ms/step - loss: 0.0355 - accuracy: 0.9719 - val_loss: 0.0288 - val_accuracy: 0.9565 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0278 - accuracy: 0.9719 - val_loss: 0.0073 - val_accuracy: 0.9739 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0226 - accuracy: 0.9741 - val_loss: 0.0206 - val_accuracy: 0.9652 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "232/232 [==============================] - 2s 7ms/step - loss: 0.0382 - accuracy: 0.9676 - val_loss: 0.0804 - val_accuracy: 0.9217 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "225/232 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9644\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 2s 7ms/step - loss: 0.0310 - accuracy: 0.9611 - val_loss: 0.0580 - val_accuracy: 0.9130 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0274 - accuracy: 0.9719 - val_loss: 0.0616 - val_accuracy: 0.9217 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "231/232 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.9827Restoring model weights from the end of the best epoch: 2.\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9827 - val_loss: 0.0558 - val_accuracy: 0.9217 - lr: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Average Accuracy:  0.8241079460269866\n",
            "Accuracy:  0.9489595202398797\n",
            "Average Normalized Accuracy:  0.8370464767616191\n",
            "Average Precision:  0.8692012421052719\n",
            "Average Recall:  0.8427544307828821\n",
            "F1 score: 0.8557735572561871\n",
            "Grand Mean: 0.8629738621954711\n"
          ]
        }
      ],
      "source": [
        "model_s3g = keras.Sequential([\n",
        "    keras.layers.Input(shape=(None, 400)),\n",
        "    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(5, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Load your data and preprocess it\n",
        "train_features = np.array(df['s3g_matrix_2g'].tolist())\n",
        "train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n",
        "\n",
        "train_features = train_features.reshape(-1, 400)\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "# Initialize a list to store accuracy scores\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "acc_scores = []\n",
        "acc_norm = []\n",
        "\n",
        "# Iterate over each sample for LOOCV\n",
        "for train_index, test_index in kf.split(train_features):\n",
        "    X_train, X_test = train_features[train_index], train_features[test_index]\n",
        "    y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
        "\n",
        "    # Compile the model and set up callbacks (as in your code)\n",
        "    model_s3g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=5, verbose=1, restore_best_weights=True)\n",
        "    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "    callbacks = [early_stopping, lr_scheduler]\n",
        "\n",
        "    batch_size = 2\n",
        "    model_s3g.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "    # Make predictions on the current test sample\n",
        "    y_pred = model_s3g.predict(X_test)\n",
        "\n",
        "\n",
        "    # Calculate and store the accuracy for this fold\n",
        "    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
        "    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    acc_scores.append(norm_accuracy(y_test, y_pred))\n",
        "    acc_norm.append(calculate_accuracy(y_test, y_pred))\n",
        "\n",
        "# Calculate the average accuracy across all folds\n",
        "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "avg_precision = sum(precision_scores) / len(precision_scores)\n",
        "avg_acc_norm = sum(acc_norm)/len(acc_norm)\n",
        "avg_recall = sum(recall_scores) / len(recall_scores)\n",
        "avg_acc = sum(acc_scores)/len(acc_scores)\n",
        "f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
        "grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n",
        "# Print the average accuracy\n",
        "print(\"Average Accuracy: \", average_accuracy)\n",
        "print(\"Accuracy: \", avg_acc)\n",
        "print(\"Average Normalized Accuracy: \", avg_acc_norm)\n",
        "print(\"Average Precision: \", avg_precision)\n",
        "print(\"Average Recall: \", avg_recall)\n",
        "print('F1 score:', f1)\n",
        "print('Grand Mean:', grand_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCplcYgUkmAb"
      },
      "source": [
        "### s4g_matrix_2g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoM9MwKlklFK",
        "outputId": "25b8e232-b396-4872-e229-d23fd0bceb80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 2s 5ms/step - loss: 0.5175 - accuracy: 0.3312 - val_loss: 0.4213 - val_accuracy: 0.4569 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.3684 - accuracy: 0.6169 - val_loss: 0.4498 - val_accuracy: 0.4655 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.2475 - accuracy: 0.7532 - val_loss: 0.4963 - val_accuracy: 0.4655 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1434 - accuracy: 0.8896 - val_loss: 0.6296 - val_accuracy: 0.4655 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0878 - accuracy: 0.9242 - val_loss: 0.7585 - val_accuracy: 0.4828 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.0526 - accuracy: 0.9567 - val_loss: 0.7584 - val_accuracy: 0.5172 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0311 - accuracy: 0.9654 - val_loss: 0.8743 - val_accuracy: 0.4224 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0270 - accuracy: 0.9740 - val_loss: 0.9541 - val_accuracy: 0.4224 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9738\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0293 - accuracy: 0.9740 - val_loss: 0.9824 - val_accuracy: 0.4483 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9654 - val_loss: 1.0077 - val_accuracy: 0.4569 - lr: 5.0000e-04\n",
            "Epoch 11/15\n",
            "225/231 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9778Restoring model weights from the end of the best epoch: 6.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0073 - accuracy: 0.9784 - val_loss: 1.0584 - val_accuracy: 0.4397 - lr: 5.0000e-04\n",
            "Epoch 11: early stopping\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "231/231 [==============================] - 2s 4ms/step - loss: 0.1977 - accuracy: 0.8485 - val_loss: 0.0525 - val_accuracy: 0.9655 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0819 - accuracy: 0.9091 - val_loss: 0.0478 - val_accuracy: 0.9569 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0376 - accuracy: 0.9459 - val_loss: 0.0471 - val_accuracy: 0.9483 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9870\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0134 - accuracy: 0.9870 - val_loss: 0.0593 - val_accuracy: 0.9483 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.9784 - val_loss: 0.0644 - val_accuracy: 0.9397 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "217/231 [===========================>..] - ETA: 0s - loss: 0.0050 - accuracy: 0.9816Restoring model weights from the end of the best epoch: 1.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9805 - val_loss: 0.0760 - val_accuracy: 0.9310 - lr: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "231/231 [==============================] - 2s 4ms/step - loss: 0.0927 - accuracy: 0.9286 - val_loss: 0.0577 - val_accuracy: 0.9138 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0465 - accuracy: 0.9545 - val_loss: 0.0342 - val_accuracy: 0.9138 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0303 - accuracy: 0.9762 - val_loss: 0.0641 - val_accuracy: 0.9397 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0137 - accuracy: 0.9805 - val_loss: 0.0762 - val_accuracy: 0.9310 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.9827 - val_loss: 0.1008 - val_accuracy: 0.8879 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "229/231 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9803\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.9805 - val_loss: 0.0910 - val_accuracy: 0.8793 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9805 - val_loss: 0.0913 - val_accuracy: 0.8879 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9805Restoring model weights from the end of the best epoch: 3.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9805 - val_loss: 0.1004 - val_accuracy: 0.8793 - lr: 5.0000e-04\n",
            "Epoch 8: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "232/232 [==============================] - 2s 5ms/step - loss: 0.0462 - accuracy: 0.9525 - val_loss: 0.0048 - val_accuracy: 0.9652 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9633 - val_loss: 0.0174 - val_accuracy: 0.9565 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0209 - accuracy: 0.9806 - val_loss: 0.0237 - val_accuracy: 0.9652 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "232/232 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9827\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0158 - accuracy: 0.9827 - val_loss: 0.0191 - val_accuracy: 0.9478 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0161 - accuracy: 0.9741 - val_loss: 0.0214 - val_accuracy: 0.9478 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "225/232 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9778Restoring model weights from the end of the best epoch: 1.\n",
            "232/232 [==============================] - 1s 6ms/step - loss: 0.0061 - accuracy: 0.9762 - val_loss: 0.0213 - val_accuracy: 0.9565 - lr: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "232/232 [==============================] - 3s 5ms/step - loss: 0.0410 - accuracy: 0.9568 - val_loss: 0.0396 - val_accuracy: 0.9565 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0449 - accuracy: 0.9611 - val_loss: 0.0305 - val_accuracy: 0.9739 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0216 - accuracy: 0.9698 - val_loss: 0.0515 - val_accuracy: 0.9565 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0203 - accuracy: 0.9676 - val_loss: 0.0674 - val_accuracy: 0.9217 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0218 - accuracy: 0.9654 - val_loss: 0.0278 - val_accuracy: 0.9826 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.9719 - val_loss: 0.0395 - val_accuracy: 0.9652 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.9741 - val_loss: 0.0513 - val_accuracy: 0.9565 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "219/232 [===========================>..] - ETA: 0s - loss: 0.0132 - accuracy: 0.9635\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0132 - accuracy: 0.9590 - val_loss: 0.0560 - val_accuracy: 0.9304 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0124 - accuracy: 0.9870 - val_loss: 0.0457 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
            "Epoch 10/15\n",
            "232/232 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9870Restoring model weights from the end of the best epoch: 5.\n",
            "232/232 [==============================] - 1s 6ms/step - loss: 0.0097 - accuracy: 0.9870 - val_loss: 0.0535 - val_accuracy: 0.9478 - lr: 5.0000e-04\n",
            "Epoch 10: early stopping\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "Average Accuracy:  0.8551424287856072\n",
            "Accuracy:  0.952062968515742\n",
            "Average Normalized Accuracy:  0.8695252373813094\n",
            "Average Precision:  0.8779493282460358\n",
            "Average Recall:  0.8762652135758622\n",
            "F1 score: 0.8771064625029251\n",
            "Grand Mean: 0.8846752731679137\n"
          ]
        }
      ],
      "source": [
        "model_s4g = keras.Sequential([\n",
        "    keras.layers.Input(shape=(None, 400)),\n",
        "    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(5, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Load your data and preprocess it\n",
        "train_features = np.array(df['s4g_matrix_2g'].tolist())\n",
        "train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n",
        "\n",
        "train_features = train_features.reshape(-1, 400)\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "# Initialize a list to store accuracy scores\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "acc_scores = []\n",
        "acc_norm = []\n",
        "\n",
        "# Iterate over each sample for LOOCV\n",
        "for train_index, test_index in kf.split(train_features):\n",
        "    X_train, X_test = train_features[train_index], train_features[test_index]\n",
        "    y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
        "\n",
        "    # Compile the model and set up callbacks (as in your code)\n",
        "    model_s4g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=5, verbose=1, restore_best_weights=True)\n",
        "    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "    callbacks = [early_stopping, lr_scheduler]\n",
        "\n",
        "    batch_size = 2\n",
        "    model_s4g.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "    # Make predictions on the current test sample\n",
        "    y_pred = model_s4g.predict(X_test)\n",
        "\n",
        "\n",
        "    # Calculate and store the accuracy for this fold\n",
        "    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
        "    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    acc_scores.append(norm_accuracy(y_test, y_pred))\n",
        "    acc_norm.append(calculate_accuracy(y_test, y_pred))\n",
        "\n",
        "# Calculate the average accuracy across all folds\n",
        "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "avg_precision = sum(precision_scores) / len(precision_scores)\n",
        "avg_acc_norm = sum(acc_norm)/len(acc_norm)\n",
        "avg_recall = sum(recall_scores) / len(recall_scores)\n",
        "avg_acc = sum(acc_scores)/len(acc_scores)\n",
        "f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
        "grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n",
        "# Print the average accuracy\n",
        "print(\"Average Accuracy: \", average_accuracy)\n",
        "print(\"Accuracy: \", avg_acc)\n",
        "print(\"Average Normalized Accuracy: \", avg_acc_norm)\n",
        "print(\"Average Precision: \", avg_precision)\n",
        "print(\"Average Recall: \", avg_recall)\n",
        "print('F1 score:', f1)\n",
        "print('Grand Mean:', grand_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6GCpbLvk5bu"
      },
      "source": [
        "### s0g_matrix_3g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7_4Rnj4k45t",
        "outputId": "d01ca689-62d0-4ffd-fd9f-a491c3682a48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 3s 5ms/step - loss: 0.5396 - accuracy: 0.3052 - val_loss: 0.4147 - val_accuracy: 0.4741 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.4346 - accuracy: 0.4394 - val_loss: 0.3881 - val_accuracy: 0.5259 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.4110 - accuracy: 0.4719 - val_loss: 0.4133 - val_accuracy: 0.4655 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.3752 - accuracy: 0.5606 - val_loss: 0.3666 - val_accuracy: 0.5259 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.3539 - accuracy: 0.5779 - val_loss: 0.3626 - val_accuracy: 0.5603 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.3360 - accuracy: 0.6190 - val_loss: 0.3875 - val_accuracy: 0.5345 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.2886 - accuracy: 0.6710 - val_loss: 0.3766 - val_accuracy: 0.5431 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.2771 - accuracy: 0.7127\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.2770 - accuracy: 0.7121 - val_loss: 0.3782 - val_accuracy: 0.5431 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.2125 - accuracy: 0.7944 - val_loss: 0.3855 - val_accuracy: 0.5517 - lr: 5.0000e-04\n",
            "Epoch 10/15\n",
            "223/231 [===========================>..] - ETA: 0s - loss: 0.1798 - accuracy: 0.8184Restoring model weights from the end of the best epoch: 5.\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.1824 - accuracy: 0.8117 - val_loss: 0.4732 - val_accuracy: 0.5431 - lr: 5.0000e-04\n",
            "Epoch 10: early stopping\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "231/231 [==============================] - 4s 5ms/step - loss: 0.3483 - accuracy: 0.6212 - val_loss: 0.3272 - val_accuracy: 0.5776 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.3291 - accuracy: 0.6212 - val_loss: 0.3180 - val_accuracy: 0.6207 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.2796 - accuracy: 0.6775 - val_loss: 0.2814 - val_accuracy: 0.6810 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.2723 - accuracy: 0.6710 - val_loss: 0.3283 - val_accuracy: 0.5948 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.2653 - accuracy: 0.7359 - val_loss: 0.3340 - val_accuracy: 0.5690 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.7662\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 2s 7ms/step - loss: 0.2229 - accuracy: 0.7662 - val_loss: 0.3328 - val_accuracy: 0.5776 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.1738 - accuracy: 0.8268 - val_loss: 0.4003 - val_accuracy: 0.5431 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "222/231 [===========================>..] - ETA: 0s - loss: 0.1546 - accuracy: 0.8536Restoring model weights from the end of the best epoch: 3.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1539 - accuracy: 0.8528 - val_loss: 0.3707 - val_accuracy: 0.5862 - lr: 5.0000e-04\n",
            "Epoch 8: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "231/231 [==============================] - 3s 6ms/step - loss: 0.2906 - accuracy: 0.6732 - val_loss: 0.2573 - val_accuracy: 0.7328 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.2542 - accuracy: 0.7273 - val_loss: 0.2513 - val_accuracy: 0.7672 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.2281 - accuracy: 0.7576 - val_loss: 0.3150 - val_accuracy: 0.6552 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.2167 - accuracy: 0.7684 - val_loss: 0.3337 - val_accuracy: 0.6466 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "219/231 [===========================>..] - ETA: 0s - loss: 0.1764 - accuracy: 0.8311\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1789 - accuracy: 0.8268 - val_loss: 0.2921 - val_accuracy: 0.6810 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1291 - accuracy: 0.8745 - val_loss: 0.3351 - val_accuracy: 0.6983 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "223/231 [===========================>..] - ETA: 0s - loss: 0.1027 - accuracy: 0.9058Restoring model weights from the end of the best epoch: 2.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9048 - val_loss: 0.2914 - val_accuracy: 0.6897 - lr: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "232/232 [==============================] - 2s 5ms/step - loss: 0.2699 - accuracy: 0.7171 - val_loss: 0.1852 - val_accuracy: 0.8783 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.2440 - accuracy: 0.7387 - val_loss: 0.1847 - val_accuracy: 0.8261 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.2173 - accuracy: 0.7840 - val_loss: 0.1686 - val_accuracy: 0.8696 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "229/232 [============================>.] - ETA: 0s - loss: 0.1835 - accuracy: 0.8122\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 2s 7ms/step - loss: 0.1843 - accuracy: 0.8099 - val_loss: 0.1667 - val_accuracy: 0.8609 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "232/232 [==============================] - 2s 7ms/step - loss: 0.1470 - accuracy: 0.8575 - val_loss: 0.1372 - val_accuracy: 0.8696 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.1218 - accuracy: 0.8661 - val_loss: 0.1482 - val_accuracy: 0.8870 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.1073 - accuracy: 0.9093 - val_loss: 0.1303 - val_accuracy: 0.9130 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0963 - accuracy: 0.8834 - val_loss: 0.1353 - val_accuracy: 0.9043 - lr: 5.0000e-04\n",
            "Epoch 9/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0805 - accuracy: 0.9330 - val_loss: 0.1443 - val_accuracy: 0.8783 - lr: 5.0000e-04\n",
            "Epoch 10/15\n",
            "231/232 [============================>.] - ETA: 0s - loss: 0.0677 - accuracy: 0.9372\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0675 - accuracy: 0.9374 - val_loss: 0.1866 - val_accuracy: 0.8261 - lr: 5.0000e-04\n",
            "Epoch 11/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0476 - accuracy: 0.9568 - val_loss: 0.1630 - val_accuracy: 0.8696 - lr: 2.5000e-04\n",
            "Epoch 12/15\n",
            "222/232 [===========================>..] - ETA: 0s - loss: 0.0403 - accuracy: 0.9617Restoring model weights from the end of the best epoch: 7.\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0391 - accuracy: 0.9633 - val_loss: 0.1703 - val_accuracy: 0.8783 - lr: 2.5000e-04\n",
            "Epoch 12: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "232/232 [==============================] - 2s 5ms/step - loss: 0.1579 - accuracy: 0.8553 - val_loss: 0.1741 - val_accuracy: 0.8435 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 1s 6ms/step - loss: 0.1404 - accuracy: 0.8661 - val_loss: 0.1964 - val_accuracy: 0.7826 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 2s 7ms/step - loss: 0.1222 - accuracy: 0.8834 - val_loss: 0.1710 - val_accuracy: 0.8348 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "223/232 [===========================>..] - ETA: 0s - loss: 0.0888 - accuracy: 0.9148\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0873 - accuracy: 0.9158 - val_loss: 0.1944 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0605 - accuracy: 0.9460 - val_loss: 0.1348 - val_accuracy: 0.8435 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "226/232 [============================>.] - ETA: 0s - loss: 0.0439 - accuracy: 0.9690Restoring model weights from the end of the best epoch: 1.\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0449 - accuracy: 0.9676 - val_loss: 0.1550 - val_accuracy: 0.8261 - lr: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Average Accuracy:  0.6458470764617691\n",
            "Accuracy:  0.8991034482758616\n",
            "Average Normalized Accuracy:  0.6654597701149425\n",
            "Average Precision:  0.7704268353732937\n",
            "Average Recall:  0.6569510750226375\n",
            "F1 score: 0.7091783248689633\n",
            "Grand Mean: 0.7244944216862447\n"
          ]
        }
      ],
      "source": [
        "model_s0g_3g = keras.Sequential([\n",
        "    keras.layers.Input(shape=(None, 400)),\n",
        "    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(5, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Load your data and preprocess it\n",
        "train_features = np.array(df['s0g_matrix_3gram'].tolist())\n",
        "train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n",
        "\n",
        "train_features = train_features.reshape(-1, 400)\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "# Initialize a list to store accuracy scores\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "acc_scores = []\n",
        "acc_norm = []\n",
        "\n",
        "# Iterate over each sample for LOOCV\n",
        "for train_index, test_index in kf.split(train_features):\n",
        "    X_train, X_test = train_features[train_index], train_features[test_index]\n",
        "    y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
        "\n",
        "    # Compile the model and set up callbacks (as in your code)\n",
        "    model_s0g_3g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=5, verbose=1, restore_best_weights=True)\n",
        "    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "    callbacks = [early_stopping, lr_scheduler]\n",
        "\n",
        "    batch_size = 2\n",
        "    model_s0g_3g.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "    # Make predictions on the current test sample\n",
        "    y_pred = model_s0g_3g.predict(X_test)\n",
        "\n",
        "\n",
        "    # Calculate and store the accuracy for this fold\n",
        "    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
        "    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    acc_scores.append(norm_accuracy(y_test, y_pred))\n",
        "    acc_norm.append(calculate_accuracy(y_test, y_pred))\n",
        "\n",
        "# Calculate the average accuracy across all folds\n",
        "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "avg_precision = sum(precision_scores) / len(precision_scores)\n",
        "avg_acc_norm = sum(acc_norm)/len(acc_norm)\n",
        "avg_recall = sum(recall_scores) / len(recall_scores)\n",
        "avg_acc = sum(acc_scores)/len(acc_scores)\n",
        "f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
        "grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n",
        "# Print the average accuracy\n",
        "print(\"Average Accuracy: \", average_accuracy)\n",
        "print(\"Accuracy: \", avg_acc)\n",
        "print(\"Average Normalized Accuracy: \", avg_acc_norm)\n",
        "print(\"Average Precision: \", avg_precision)\n",
        "print(\"Average Recall: \", avg_recall)\n",
        "print('F1 score:', f1)\n",
        "print('Grand Mean:', grand_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAD0yP0fljoT"
      },
      "source": [
        "### s1g_matrix_3g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "LJnIBTaolmYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7d87ba2-ee64-45d4-c273-fb9e5d9037ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 2s 5ms/step - loss: 0.4969 - accuracy: 0.3766 - val_loss: 0.3853 - val_accuracy: 0.4655 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.3891 - accuracy: 0.5325 - val_loss: 0.3718 - val_accuracy: 0.5259 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.3508 - accuracy: 0.5866 - val_loss: 0.3484 - val_accuracy: 0.5776 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.2917 - accuracy: 0.6883 - val_loss: 0.3957 - val_accuracy: 0.5172 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 3s 13ms/step - loss: 0.2081 - accuracy: 0.8009 - val_loss: 0.3946 - val_accuracy: 0.5690 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "230/231 [============================>.] - ETA: 0s - loss: 0.1701 - accuracy: 0.8217\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 2s 8ms/step - loss: 0.1695 - accuracy: 0.8225 - val_loss: 0.5037 - val_accuracy: 0.5172 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 2s 8ms/step - loss: 0.0959 - accuracy: 0.9329 - val_loss: 0.5007 - val_accuracy: 0.5690 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9502Restoring model weights from the end of the best epoch: 3.\n",
            "231/231 [==============================] - 2s 8ms/step - loss: 0.0605 - accuracy: 0.9502 - val_loss: 0.6217 - val_accuracy: 0.5086 - lr: 5.0000e-04\n",
            "Epoch 8: early stopping\n",
            "4/4 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 3s 5ms/step - loss: 0.3284 - accuracy: 0.6429 - val_loss: 0.2718 - val_accuracy: 0.6466 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.2577 - accuracy: 0.7186 - val_loss: 0.2946 - val_accuracy: 0.6379 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.2014 - accuracy: 0.8139 - val_loss: 0.2535 - val_accuracy: 0.6983 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.1351 - accuracy: 0.8550 - val_loss: 0.2883 - val_accuracy: 0.6466 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0944 - accuracy: 0.9221 - val_loss: 0.4023 - val_accuracy: 0.5517 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "225/231 [============================>.] - ETA: 0s - loss: 0.1031 - accuracy: 0.9156\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1021 - accuracy: 0.9156 - val_loss: 0.3704 - val_accuracy: 0.5948 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0500 - accuracy: 0.9524 - val_loss: 0.3899 - val_accuracy: 0.6638 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9697Restoring model weights from the end of the best epoch: 3.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0238 - accuracy: 0.9697 - val_loss: 0.3798 - val_accuracy: 0.6724 - lr: 5.0000e-04\n",
            "Epoch 8: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "231/231 [==============================] - 2s 5ms/step - loss: 0.2022 - accuracy: 0.7619 - val_loss: 0.1319 - val_accuracy: 0.8707 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1375 - accuracy: 0.8723 - val_loss: 0.1161 - val_accuracy: 0.9052 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0840 - accuracy: 0.9286 - val_loss: 0.2838 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0895 - accuracy: 0.9221 - val_loss: 0.1295 - val_accuracy: 0.8879 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "217/231 [===========================>..] - ETA: 0s - loss: 0.0548 - accuracy: 0.9516\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0535 - accuracy: 0.9545 - val_loss: 0.1864 - val_accuracy: 0.8276 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9848 - val_loss: 0.1608 - val_accuracy: 0.8793 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "226/231 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9845Restoring model weights from the end of the best epoch: 2.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9848 - val_loss: 0.1813 - val_accuracy: 0.8276 - lr: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Epoch 1/15\n",
            "232/232 [==============================] - 3s 6ms/step - loss: 0.1141 - accuracy: 0.9050 - val_loss: 0.1124 - val_accuracy: 0.9043 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0841 - accuracy: 0.9374 - val_loss: 0.1863 - val_accuracy: 0.8174 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0745 - accuracy: 0.9374 - val_loss: 0.0755 - val_accuracy: 0.9565 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0336 - accuracy: 0.9654 - val_loss: 0.0657 - val_accuracy: 0.9391 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0334 - accuracy: 0.9676 - val_loss: 0.0800 - val_accuracy: 0.9478 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "228/232 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9737\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9741 - val_loss: 0.1049 - val_accuracy: 0.9130 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0208 - accuracy: 0.9741 - val_loss: 0.1000 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "229/232 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9891Restoring model weights from the end of the best epoch: 3.\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 0.9892 - val_loss: 0.0800 - val_accuracy: 0.9304 - lr: 5.0000e-04\n",
            "Epoch 8: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "232/232 [==============================] - 3s 8ms/step - loss: 0.0772 - accuracy: 0.9309 - val_loss: 0.0629 - val_accuracy: 0.9739 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0489 - accuracy: 0.9546 - val_loss: 0.0291 - val_accuracy: 0.9565 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0414 - accuracy: 0.9676 - val_loss: 0.0339 - val_accuracy: 0.9739 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "223/232 [===========================>..] - ETA: 0s - loss: 0.0393 - accuracy: 0.9641\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0391 - accuracy: 0.9633 - val_loss: 0.1036 - val_accuracy: 0.9130 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0220 - accuracy: 0.9719 - val_loss: 0.0985 - val_accuracy: 0.9565 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "232/232 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9827Restoring model weights from the end of the best epoch: 1.\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9827 - val_loss: 0.0360 - val_accuracy: 0.9565 - lr: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Average Accuracy:  0.7324737631184408\n",
            "Accuracy:  0.9302758620689652\n",
            "Average Normalized Accuracy:  0.7489355322338831\n",
            "Average Precision:  0.8754906623181362\n",
            "Average Recall:  0.7354354418432127\n",
            "F1 score: 0.7993747949186579\n",
            "Grand Mean: 0.803664342750216\n"
          ]
        }
      ],
      "source": [
        "model_s1g_3g = keras.Sequential([\n",
        "    keras.layers.Input(shape=(None, 400)),\n",
        "    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(5, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Load your data and preprocess it\n",
        "train_features = np.array(df['s1g_matrix_3gram'].tolist())\n",
        "train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n",
        "\n",
        "train_features = train_features.reshape(-1, 400)\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "# Initialize a list to store accuracy scores\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "acc_scores = []\n",
        "acc_norm = []\n",
        "\n",
        "# Iterate over each sample for LOOCV\n",
        "for train_index, test_index in kf.split(train_features):\n",
        "    X_train, X_test = train_features[train_index], train_features[test_index]\n",
        "    y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
        "\n",
        "    # Compile the model and set up callbacks (as in your code)\n",
        "    model_s1g_3g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=5, verbose=1, restore_best_weights=True)\n",
        "    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "    callbacks = [early_stopping, lr_scheduler]\n",
        "\n",
        "    batch_size = 2\n",
        "    model_s1g_3g.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "    # Make predictions on the current test sample\n",
        "    y_pred = model_s1g_3g.predict(X_test)\n",
        "\n",
        "\n",
        "    # Calculate and store the accuracy for this fold\n",
        "    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
        "    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    acc_scores.append(norm_accuracy(y_test, y_pred))\n",
        "    acc_norm.append(calculate_accuracy(y_test, y_pred))\n",
        "\n",
        "# Calculate the average accuracy across all folds\n",
        "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "avg_precision = sum(precision_scores) / len(precision_scores)\n",
        "avg_acc_norm = sum(acc_norm)/len(acc_norm)\n",
        "avg_recall = sum(recall_scores) / len(recall_scores)\n",
        "avg_acc = sum(acc_scores)/len(acc_scores)\n",
        "f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
        "grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n",
        "# Print the average accuracy\n",
        "print(\"Average Accuracy: \", average_accuracy)\n",
        "print(\"Accuracy: \", avg_acc)\n",
        "print(\"Average Normalized Accuracy: \", avg_acc_norm)\n",
        "print(\"Average Precision: \", avg_precision)\n",
        "print(\"Average Recall: \", avg_recall)\n",
        "print('F1 score:', f1)\n",
        "print('Grand Mean:', grand_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-Cq5KVKlj23"
      },
      "source": [
        "### s2g_matrix_3g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "yVNMsrG3lnVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7733063-4eb9-486d-dfd9-19837113bd6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 2s 5ms/step - loss: 0.4670 - accuracy: 0.4069 - val_loss: 0.3759 - val_accuracy: 0.5172 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.3475 - accuracy: 0.6234 - val_loss: 0.3698 - val_accuracy: 0.5345 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.2446 - accuracy: 0.7468 - val_loss: 0.4157 - val_accuracy: 0.5172 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.1724 - accuracy: 0.8377 - val_loss: 0.4317 - val_accuracy: 0.5259 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.1036 - accuracy: 0.9091 - val_loss: 0.5458 - val_accuracy: 0.5862 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0744 - accuracy: 0.9416 - val_loss: 0.6262 - val_accuracy: 0.5345 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0570 - accuracy: 0.9567 - val_loss: 0.6454 - val_accuracy: 0.5690 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "228/231 [============================>.] - ETA: 0s - loss: 0.0332 - accuracy: 0.9671\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0329 - accuracy: 0.9675 - val_loss: 0.6926 - val_accuracy: 0.5086 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0186 - accuracy: 0.9827 - val_loss: 0.7198 - val_accuracy: 0.5259 - lr: 5.0000e-04\n",
            "Epoch 10/15\n",
            "219/231 [===========================>..] - ETA: 0s - loss: 0.0119 - accuracy: 0.9840Restoring model weights from the end of the best epoch: 5.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9848 - val_loss: 0.7922 - val_accuracy: 0.5259 - lr: 5.0000e-04\n",
            "Epoch 10: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "231/231 [==============================] - 2s 5ms/step - loss: 0.1840 - accuracy: 0.8463 - val_loss: 0.0755 - val_accuracy: 0.9569 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0986 - accuracy: 0.9048 - val_loss: 0.0671 - val_accuracy: 0.9569 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0490 - accuracy: 0.9502 - val_loss: 0.0604 - val_accuracy: 0.9310 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9632\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 6ms/step - loss: 0.0301 - accuracy: 0.9632 - val_loss: 0.0941 - val_accuracy: 0.8793 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.0239 - accuracy: 0.9719 - val_loss: 0.0835 - val_accuracy: 0.9138 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9827Restoring model weights from the end of the best epoch: 1.\n",
            "231/231 [==============================] - 1s 5ms/step - loss: 0.0129 - accuracy: 0.9827 - val_loss: 0.0960 - val_accuracy: 0.8966 - lr: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "231/231 [==============================] - 2s 5ms/step - loss: 0.1131 - accuracy: 0.8983 - val_loss: 0.0534 - val_accuracy: 0.9569 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0619 - accuracy: 0.9416 - val_loss: 0.0751 - val_accuracy: 0.9397 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0280 - accuracy: 0.9827 - val_loss: 0.0611 - val_accuracy: 0.9397 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "223/231 [===========================>..] - ETA: 0s - loss: 0.0399 - accuracy: 0.9731\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0388 - accuracy: 0.9740 - val_loss: 0.0638 - val_accuracy: 0.9483 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9848 - val_loss: 0.0575 - val_accuracy: 0.9483 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "217/231 [===========================>..] - ETA: 0s - loss: 0.0057 - accuracy: 0.9747Restoring model weights from the end of the best epoch: 1.\n",
            "231/231 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9740 - val_loss: 0.0736 - val_accuracy: 0.9310 - lr: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n",
            "232/232 [==============================] - 3s 6ms/step - loss: 0.0816 - accuracy: 0.9395 - val_loss: 0.0182 - val_accuracy: 0.9739 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 2s 7ms/step - loss: 0.0449 - accuracy: 0.9546 - val_loss: 0.0157 - val_accuracy: 0.9739 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 1s 6ms/step - loss: 0.0321 - accuracy: 0.9698 - val_loss: 0.0195 - val_accuracy: 0.9739 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "224/232 [===========================>..] - ETA: 0s - loss: 0.0214 - accuracy: 0.9821\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0207 - accuracy: 0.9827 - val_loss: 0.0339 - val_accuracy: 0.9391 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0192 - accuracy: 0.9719 - val_loss: 0.0295 - val_accuracy: 0.9652 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "228/232 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9803Restoring model weights from the end of the best epoch: 1.\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.9806 - val_loss: 0.0293 - val_accuracy: 0.9478 - lr: 5.0000e-04\n",
            "Epoch 6: early stopping\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "232/232 [==============================] - 2s 5ms/step - loss: 0.0537 - accuracy: 0.9460 - val_loss: 0.0664 - val_accuracy: 0.9304 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0395 - accuracy: 0.9698 - val_loss: 0.0403 - val_accuracy: 0.9652 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0336 - accuracy: 0.9827 - val_loss: 0.0592 - val_accuracy: 0.9217 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "232/232 [==============================] - 1s 4ms/step - loss: 0.0225 - accuracy: 0.9870 - val_loss: 0.1656 - val_accuracy: 0.9130 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "225/232 [============================>.] - ETA: 0s - loss: 0.0325 - accuracy: 0.9689\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 1s 5ms/step - loss: 0.0316 - accuracy: 0.9698 - val_loss: 0.0658 - val_accuracy: 0.9391 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "232/232 [==============================] - 2s 8ms/step - loss: 0.0115 - accuracy: 0.9849 - val_loss: 0.0512 - val_accuracy: 0.9478 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "224/232 [===========================>..] - ETA: 0s - loss: 0.0034 - accuracy: 0.9799Restoring model weights from the end of the best epoch: 2.\n",
            "232/232 [==============================] - 2s 8ms/step - loss: 0.0033 - accuracy: 0.9806 - val_loss: 0.0454 - val_accuracy: 0.9478 - lr: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Average Accuracy:  0.8481259370314842\n",
            "Accuracy:  0.9520299850074961\n",
            "Average Normalized Accuracy:  0.8720339830084958\n",
            "Average Precision:  0.8996116579782683\n",
            "Average Recall:  0.8694369455394592\n",
            "F1 score: 0.8842669562939187\n",
            "Grand Mean: 0.887584244143187\n"
          ]
        }
      ],
      "source": [
        "model_s2g_3g = keras.Sequential([\n",
        "    keras.layers.Input(shape=(None, 400)),\n",
        "    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(5, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Load your data and preprocess it\n",
        "train_features = np.array(df['s2g_matrix_3gram'].tolist())\n",
        "train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n",
        "\n",
        "train_features = train_features.reshape(-1, 400)\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "# Initialize a list to store accuracy scores\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "acc_scores = []\n",
        "acc_norm = []\n",
        "\n",
        "# Iterate over each sample for LOOCV\n",
        "for train_index, test_index in kf.split(train_features):\n",
        "    X_train, X_test = train_features[train_index], train_features[test_index]\n",
        "    y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
        "\n",
        "    # Compile the model and set up callbacks (as in your code)\n",
        "    model_s2g_3g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=5, verbose=1, restore_best_weights=True)\n",
        "    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "    callbacks = [early_stopping, lr_scheduler]\n",
        "\n",
        "    batch_size = 2\n",
        "    model_s2g_3g.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "    # Make predictions on the current test sample\n",
        "    y_pred = model_s2g_3g.predict(X_test)\n",
        "\n",
        "\n",
        "    # Calculate and store the accuracy for this fold\n",
        "    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
        "    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    acc_scores.append(norm_accuracy(y_test, y_pred))\n",
        "    acc_norm.append(calculate_accuracy(y_test, y_pred))\n",
        "\n",
        "# Calculate the average accuracy across all folds\n",
        "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "avg_precision = sum(precision_scores) / len(precision_scores)\n",
        "avg_acc_norm = sum(acc_norm)/len(acc_norm)\n",
        "avg_recall = sum(recall_scores) / len(recall_scores)\n",
        "avg_acc = sum(acc_scores)/len(acc_scores)\n",
        "f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
        "grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n",
        "# Print the average accuracy\n",
        "print(\"Average Accuracy: \", average_accuracy)\n",
        "print(\"Accuracy: \", avg_acc)\n",
        "print(\"Average Normalized Accuracy: \", avg_acc_norm)\n",
        "print(\"Average Precision: \", avg_precision)\n",
        "print(\"Average Recall: \", avg_recall)\n",
        "print('F1 score:', f1)\n",
        "print('Grand Mean:', grand_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJOvy0PRl_Sb"
      },
      "source": [
        "### Trigram S2G - LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUdpN-temWyD",
        "outputId": "c27da568-98ba-4d1d-e30c-708b6ef2412d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "231/231 [==============================] - 25s 71ms/step - loss: 0.4845 - accuracy: 0.3961 - val_loss: 0.3973 - val_accuracy: 0.4828 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 12s 52ms/step - loss: 0.3443 - accuracy: 0.6082 - val_loss: 0.4433 - val_accuracy: 0.5086 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 13s 57ms/step - loss: 0.2109 - accuracy: 0.7965 - val_loss: 0.4706 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 12s 54ms/step - loss: 0.0865 - accuracy: 0.9416 - val_loss: 0.5797 - val_accuracy: 0.4914 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 11s 48ms/step - loss: 0.0319 - accuracy: 0.9589 - val_loss: 0.7028 - val_accuracy: 0.5345 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0134 - accuracy: 0.9805 - val_loss: 0.7969 - val_accuracy: 0.5259 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 7s 32ms/step - loss: 0.0041 - accuracy: 0.9805 - val_loss: 0.8590 - val_accuracy: 0.5172 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - 8s 36ms/step - loss: 0.0014 - accuracy: 0.9784 - val_loss: 0.9027 - val_accuracy: 0.4914 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "231/231 [==============================] - ETA: 0s - loss: 4.7352e-04 - accuracy: 0.9762\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 7s 30ms/step - loss: 4.7352e-04 - accuracy: 0.9762 - val_loss: 0.9112 - val_accuracy: 0.5086 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "231/231 [==============================] - 8s 34ms/step - loss: 2.4969e-04 - accuracy: 0.9784 - val_loss: 0.9265 - val_accuracy: 0.5086 - lr: 5.0000e-04\n",
            "Epoch 11/15\n",
            "231/231 [==============================] - 7s 30ms/step - loss: 2.0705e-04 - accuracy: 0.9762 - val_loss: 0.9436 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
            "Epoch 12/15\n",
            "230/231 [============================>.] - ETA: 0s - loss: 1.7189e-04 - accuracy: 0.9739Restoring model weights from the end of the best epoch: 5.\n",
            "231/231 [==============================] - 8s 34ms/step - loss: 1.7186e-04 - accuracy: 0.9740 - val_loss: 0.9598 - val_accuracy: 0.4914 - lr: 5.0000e-04\n",
            "Epoch 12: early stopping\n",
            "4/4 [==============================] - 1s 13ms/step\n",
            "Epoch 1/15\n",
            "231/231 [==============================] - 13s 40ms/step - loss: 0.1845 - accuracy: 0.8398 - val_loss: 0.0414 - val_accuracy: 0.9914 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 8s 34ms/step - loss: 0.0394 - accuracy: 0.9697 - val_loss: 0.0390 - val_accuracy: 0.9914 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 7s 30ms/step - loss: 0.0134 - accuracy: 0.9784 - val_loss: 0.0331 - val_accuracy: 0.9828 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 10s 42ms/step - loss: 0.0069 - accuracy: 0.9784 - val_loss: 0.0345 - val_accuracy: 0.9741 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9805\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 7s 30ms/step - loss: 0.0087 - accuracy: 0.9805 - val_loss: 0.0574 - val_accuracy: 0.9483 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 8s 34ms/step - loss: 0.0079 - accuracy: 0.9719 - val_loss: 0.0418 - val_accuracy: 0.9655 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 7s 30ms/step - loss: 0.0026 - accuracy: 0.9805 - val_loss: 0.0419 - val_accuracy: 0.9655 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9827Restoring model weights from the end of the best epoch: 1.\n",
            "231/231 [==============================] - 8s 34ms/step - loss: 0.0016 - accuracy: 0.9827 - val_loss: 0.0420 - val_accuracy: 0.9655 - lr: 5.0000e-04\n",
            "Epoch 8: early stopping\n",
            "4/4 [==============================] - 1s 27ms/step\n",
            "Epoch 1/15\n",
            "231/231 [==============================] - 12s 34ms/step - loss: 0.0699 - accuracy: 0.9481 - val_loss: 0.0301 - val_accuracy: 0.9828 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "231/231 [==============================] - 8s 34ms/step - loss: 0.0204 - accuracy: 0.9784 - val_loss: 0.0240 - val_accuracy: 0.9741 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "231/231 [==============================] - 8s 35ms/step - loss: 0.0175 - accuracy: 0.9848 - val_loss: 0.0258 - val_accuracy: 0.9741 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "231/231 [==============================] - 7s 30ms/step - loss: 0.0148 - accuracy: 0.9805 - val_loss: 0.0246 - val_accuracy: 0.9914 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/231 [==============================] - 9s 40ms/step - loss: 0.0118 - accuracy: 0.9784 - val_loss: 0.1765 - val_accuracy: 0.9052 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "231/231 [==============================] - 7s 30ms/step - loss: 0.0392 - accuracy: 0.9610 - val_loss: 0.0691 - val_accuracy: 0.9483 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "231/231 [==============================] - 8s 35ms/step - loss: 0.0089 - accuracy: 0.9913 - val_loss: 0.1208 - val_accuracy: 0.9397 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9870\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "231/231 [==============================] - 8s 33ms/step - loss: 0.0028 - accuracy: 0.9870 - val_loss: 0.0776 - val_accuracy: 0.9569 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 3.9431e-04 - accuracy: 0.9935 - val_loss: 0.0774 - val_accuracy: 0.9569 - lr: 5.0000e-04\n",
            "Epoch 10/15\n",
            "231/231 [==============================] - 8s 34ms/step - loss: 4.2580e-04 - accuracy: 0.9870 - val_loss: 0.0787 - val_accuracy: 0.9397 - lr: 5.0000e-04\n",
            "Epoch 11/15\n",
            "231/231 [==============================] - ETA: 0s - loss: 2.4515e-04 - accuracy: 0.9913Restoring model weights from the end of the best epoch: 4.\n",
            "231/231 [==============================] - 7s 31ms/step - loss: 2.4515e-04 - accuracy: 0.9913 - val_loss: 0.0750 - val_accuracy: 0.9569 - lr: 5.0000e-04\n",
            "Epoch 11: early stopping\n",
            "4/4 [==============================] - 1s 14ms/step\n",
            "Epoch 1/15\n",
            "232/232 [==============================] - 13s 38ms/step - loss: 0.0276 - accuracy: 0.9719 - val_loss: 0.0209 - val_accuracy: 0.9565 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 8s 35ms/step - loss: 0.0377 - accuracy: 0.9719 - val_loss: 0.0251 - val_accuracy: 0.9478 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 8s 35ms/step - loss: 0.0036 - accuracy: 0.9827 - val_loss: 0.0155 - val_accuracy: 0.9565 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "232/232 [==============================] - 7s 32ms/step - loss: 0.0016 - accuracy: 0.9892 - val_loss: 0.0122 - val_accuracy: 0.9652 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "232/232 [==============================] - 8s 35ms/step - loss: 0.0014 - accuracy: 0.9849 - val_loss: 0.0026 - val_accuracy: 0.9652 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "232/232 [==============================] - 7s 31ms/step - loss: 2.7430e-04 - accuracy: 0.9892 - val_loss: 0.0037 - val_accuracy: 0.9652 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "232/232 [==============================] - 8s 35ms/step - loss: 9.4024e-05 - accuracy: 0.9870 - val_loss: 0.0031 - val_accuracy: 0.9652 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "232/232 [==============================] - ETA: 0s - loss: 5.7788e-05 - accuracy: 0.9784\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 8s 36ms/step - loss: 5.7788e-05 - accuracy: 0.9784 - val_loss: 0.0026 - val_accuracy: 0.9652 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "232/232 [==============================] - 8s 33ms/step - loss: 4.1030e-05 - accuracy: 0.9849 - val_loss: 0.0025 - val_accuracy: 0.9652 - lr: 5.0000e-04\n",
            "Epoch 10/15\n",
            "232/232 [==============================] - 8s 35ms/step - loss: 5.2224e-05 - accuracy: 0.9827 - val_loss: 0.0026 - val_accuracy: 0.9652 - lr: 5.0000e-04\n",
            "Epoch 11/15\n",
            "231/232 [============================>.] - ETA: 0s - loss: 3.4978e-05 - accuracy: 0.9827Restoring model weights from the end of the best epoch: 4.\n",
            "232/232 [==============================] - 7s 31ms/step - loss: 3.4914e-05 - accuracy: 0.9827 - val_loss: 0.0025 - val_accuracy: 0.9652 - lr: 5.0000e-04\n",
            "Epoch 11: early stopping\n",
            "4/4 [==============================] - 1s 26ms/step\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "232/232 [==============================] - 14s 38ms/step - loss: 0.0072 - accuracy: 0.9870 - val_loss: 0.0043 - val_accuracy: 0.9913 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "232/232 [==============================] - 9s 37ms/step - loss: 0.0071 - accuracy: 0.9827 - val_loss: 0.0079 - val_accuracy: 0.9652 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "232/232 [==============================] - 7s 32ms/step - loss: 0.0415 - accuracy: 0.9676 - val_loss: 0.1208 - val_accuracy: 0.8957 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "232/232 [==============================] - 8s 35ms/step - loss: 0.0230 - accuracy: 0.9784 - val_loss: 0.0353 - val_accuracy: 0.9739 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "231/232 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9827\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "232/232 [==============================] - 8s 34ms/step - loss: 0.0051 - accuracy: 0.9827 - val_loss: 0.0320 - val_accuracy: 0.9478 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "232/232 [==============================] - 9s 37ms/step - loss: 7.7287e-04 - accuracy: 0.9806 - val_loss: 0.0183 - val_accuracy: 0.9826 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "232/232 [==============================] - 8s 35ms/step - loss: 1.8536e-04 - accuracy: 0.9849 - val_loss: 0.0156 - val_accuracy: 0.9826 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "231/232 [============================>.] - ETA: 0s - loss: 1.5911e-04 - accuracy: 0.9848Restoring model weights from the end of the best epoch: 1.\n",
            "232/232 [==============================] - 7s 31ms/step - loss: 1.5877e-04 - accuracy: 0.9849 - val_loss: 0.0146 - val_accuracy: 0.9826 - lr: 5.0000e-04\n",
            "Epoch 8: early stopping\n",
            "4/4 [==============================] - 1s 14ms/step\n",
            "Average Accuracy:  0.8758320839580211\n",
            "Accuracy:  0.9617151424287854\n",
            "Average Normalized Accuracy:  0.8876211894052973\n",
            "Average Precision:  0.9095506552688117\n",
            "Average Recall:  0.8959336200308445\n",
            "F1 score: 0.9026907875352885\n",
            "Grand Mean: 0.9055572464378413\n"
          ]
        }
      ],
      "source": [
        "model_lstmsn = keras.Sequential([\n",
        "    keras.layers.Input(shape=(400,1)),\n",
        "    keras.layers.LSTM(256, return_sequences=True, kernel_initializer = 'he_normal'),\n",
        "    keras.layers.LSTM(128, return_sequences=True, kernel_initializer = 'he_normal'),  # Another LSTM layer with 64 units\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(64, activation='relu', kernel_initializer = 'he_normal'),     # Fully connected layer\n",
        "    keras.layers.Dense(5, activation='sigmoid')    # Output layer with sigmoid activation for multi-label classification\n",
        "])\n",
        "\n",
        "train_features = np.array(df['s2g_matrix_3gram'].tolist())\n",
        "train_features = train_features.reshape(-1, 400,1)\n",
        "\n",
        "train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "# Initialize a list to store accuracy scores\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "acc_scores = []\n",
        "acc_norm = []\n",
        "\n",
        "# Iterate over each sample for LOOCV\n",
        "for train_index, test_index in kf.split(train_features):\n",
        "    X_train, X_test = train_features[train_index], train_features[test_index]\n",
        "    y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
        "\n",
        "    # Compile the model and set up callbacks (as in your code)\n",
        "    model_lstmsn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=7, verbose=1, restore_best_weights=True)\n",
        "    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=4, min_lr=1e-6, verbose=1)\n",
        "    callbacks = [early_stopping, lr_scheduler]\n",
        "\n",
        "    batch_size = 2\n",
        "    model_lstmsn.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "    # Make predictions on the current test sample\n",
        "    y_pred = model_lstmsn.predict(X_test)\n",
        "\n",
        "\n",
        "    # Calculate and store the accuracy for this fold\n",
        "    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n",
        "    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    acc_scores.append(norm_accuracy(y_test, y_pred))\n",
        "    acc_norm.append(calculate_accuracy(y_test, y_pred))\n",
        "\n",
        "# Calculate the average accuracy across all folds\n",
        "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "avg_precision = sum(precision_scores) / len(precision_scores)\n",
        "avg_acc_norm = sum(acc_norm)/len(acc_norm)\n",
        "avg_recall = sum(recall_scores) / len(recall_scores)\n",
        "avg_acc = sum(acc_scores)/len(acc_scores)\n",
        "f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
        "grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n",
        "# Print the average accuracy\n",
        "print(\"Average Accuracy: \", average_accuracy)\n",
        "print(\"Accuracy: \", avg_acc)\n",
        "print(\"Average Normalized Accuracy: \", avg_acc_norm)\n",
        "print(\"Average Precision: \", avg_precision)\n",
        "print(\"Average Recall: \", avg_recall)\n",
        "print('F1 score:', f1)\n",
        "print('Grand Mean:', grand_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sDUzfC_mXdx"
      },
      "source": [
        "### Triigram S2G - XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNXME9dAmzLU",
        "outputId": "511ab354-4665-4bbb-c264-eea61e6a3b56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Atk1ZVoPmdfr",
        "outputId": "e6679d93-3edd-49f3-912f-f41969f4887c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy:  0.30277361319340323\n",
            "Accuracy:  0.8922698650674656\n",
            "Average Normalized Accuracy:  0.6058520739630184\n",
            "Average Precision:  0.5940635756735445\n",
            "Average Recall:  0.3329690205386431\n",
            "F1 score: 0.42674824539703426\n",
            "Grand Mean: 0.525779398972185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Define the XGBoost classifier\n",
        "model_xgb = xgb.XGBClassifier()\n",
        "\n",
        "# Load your data and pr0.0.eprocess it\n",
        "train_features = np.array(df['s2g_matrix_3gram'].tolist())\n",
        "train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n",
        "\n",
        "train_features = train_features.reshape(-1, 400)\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "# Initialize a list to store accuracy scores\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "# Iterate over each sample for LOOCV\n",
        "for train_index, test_index in kf.split(train_features):\n",
        "    X_train, X_test = train_features[train_index], train_features[test_index]\n",
        "    y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
        "\n",
        "    # Fit the XGBoost model to the training data\n",
        "    model_xgb.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the current test sample\n",
        "    y_pred = model_xgb.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    acc_scores.append(norm_accuracy(y_test, y_pred))\n",
        "    acc_norm.append(calculate_accuracy(y_test, y_pred))\n",
        "\n",
        "# Calculate the average accuracy across all folds\n",
        "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "avg_precision = sum(precision_scores) / len(precision_scores)\n",
        "avg_acc_norm = sum(acc_norm)/len(acc_norm)\n",
        "avg_recall = sum(recall_scores) / len(recall_scores)\n",
        "avg_acc = sum(acc_scores)/len(acc_scores)\n",
        "f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
        "grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n",
        "# Print the average accuracy\n",
        "print(\"Average Accuracy: \", average_accuracy)\n",
        "print(\"Accuracy: \", avg_acc)\n",
        "print(\"Average Normalized Accuracy: \", avg_acc_norm)\n",
        "print(\"Average Precision: \", avg_precision)\n",
        "print(\"Average Recall: \", avg_recall)\n",
        "print('F1 score:', f1)\n",
        "print('Grand Mean:', grand_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNbIMYLumerk"
      },
      "source": [
        "### Trigram S2G - KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVu7c4qHmh42",
        "outputId": "b2551c8e-605c-4049-a03e-a6b8986cac6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy:  0.3789205397301349\n",
            "Accuracy:  0.8041589205397293\n",
            "Average Normalized Accuracy:  0.39306596701649177\n",
            "Average Precision:  0.5265527870590809\n",
            "Average Recall:  0.3921810960714485\n",
            "F1 score: 0.44954050995628136\n",
            "Grand Mean: 0.4907366367288611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define the k-NN classifier\n",
        "model_knn = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (k) as needed\n",
        "\n",
        "# Load your data and preprocess it\n",
        "train_features = np.array(df['s2g_matrix_3gram'].tolist())\n",
        "train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n",
        "\n",
        "train_features = train_features.reshape(-1, 400)\n",
        "\n",
        "# Initialize K-Fold cross-validator\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "# Initialize a list to store accuracy scores\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "acc_scores = []\n",
        "acc_norm = []\n",
        "\n",
        "# Iterate over each sample for LOOCV\n",
        "for train_index, test_index in kf.split(train_features):\n",
        "    X_train, X_test = train_features[train_index], train_features[test_index]\n",
        "    y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
        "\n",
        "    # Fit the k-NN model to the training data\n",
        "    model_knn.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the current test sample\n",
        "    y_pred = model_knn.predict(X_test)\n",
        "\n",
        "    # Calculate and store the accuracy for this fold\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    acc_scores.append(norm_accuracy(y_test, y_pred))\n",
        "    acc_norm.append(calculate_accuracy(y_test, y_pred))\n",
        "\n",
        "# Calculate the average accuracy across all folds\n",
        "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "avg_precision = sum(precision_scores) / len(precision_scores)\n",
        "avg_acc_norm = sum(acc_norm)/len(acc_norm)\n",
        "avg_recall = sum(recall_scores) / len(recall_scores)\n",
        "avg_acc = sum(acc_scores)/len(acc_scores)\n",
        "f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
        "grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n",
        "# Print the average accuracy\n",
        "print(\"Average Accuracy: \", average_accuracy)\n",
        "print(\"Accuracy: \", avg_acc)\n",
        "print(\"Average Normalized Accuracy: \", avg_acc_norm)\n",
        "print(\"Average Precision: \", avg_precision)\n",
        "print(\"Average Recall: \", avg_recall)\n",
        "print('F1 score:', f1)\n",
        "print('Grand Mean:', grand_mean)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "MZoOOLtmXiNa",
        "s9T-mtoti7XD"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}